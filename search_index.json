[["index.html", "Bayes Rules! Book Club Welcome", " Bayes Rules! Book Club The R4DS Online Learning Community 2022-11-11 Welcome Welcome to the bookclub! This is a companion for the book Bayes Rules! by Alicia A. Johnson, Miles Q. Ott, and Mine Dogucu (Chapman and Hall/CRC, copyright 2022, 9780367255398). This companion is available at r4ds.io/bayes_rules. This website is being developed by the R4DS Online Learning Community. Follow along, and join the community to participate. This companion follows the R4DS Online Learning Community Code of Conduct. "],["book-club-meetings.html", "Book club meetings", " Book club meetings Each week, a volunteer will present a chapter from the book (or part of a chapter). This is the best way to learn the material. Presentations will usually consist of a review of the material, a discussion, and/or a demonstration of the principles presented in that chapter. More information about how to present is available in the github repo. Presentations will be recorded, and will be available on the R4DS Online Learning Community YouTube Channel. "],["pace.html", "Pace", " Pace We’ll try to cover 1 chapter/week, but… …It’s ok to split chapters when they feel like too much. We will try to meet every week, but will likely take some breaks for holidays, etc. Following the flow! Source: https://www.youtube.com/watch?v=zYYBtxHWE0A From: Richard McElreath, Statistical Rethinking videos "],["preface.html", "Preface ", " Preface "],["bayesian-statistics.html", "0.1 Bayesian statistics?", " 0.1 Bayesian statistics? Frequentist and Bayesian methods share: learning from data But Bayesian allows: new data + prior results easier to interpret shines when frequentist fails computational tools more accesible now "],["tips-and-tricks-from-the-authors.html", "0.2 Tips and tricks from the authors", " 0.2 Tips and tricks from the authors Learn by doing Embrace a growth mindset (we will do mistakes!) Interpret Bayes in a context (ethics and maybe more) Practice, practice, practice "],["set-up.html", "0.3 Set up", " 0.3 Set up Install rstan : https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started install.packages(c(&quot;bayesrules&quot;, &quot;tidyverse&quot;, &quot;janitor&quot;, &quot;rstanarm&quot;, &quot;bayesplot&quot;, &quot;tidybayes&quot;, &quot;broom.mixed&quot;, &quot;modelr&quot;, &quot;e1071&quot;, &quot;forcats&quot;), dependencies = TRUE) On linux (ubuntu 22) I had to update some dependencies. "],["the-authors.html", "0.4 The authors:", " 0.4 The authors: Alicia A. Johnson : Website https://ajohns24.github.io/portfolio/ Miles Q. Ott: https://twitter.com/Miles_Ott Mine Dogucu: https://twitter.com/MineDogucu "],["the-big-bayesian-picture.html", "Chapter 1 The Big (Bayesian) Picture", " Chapter 1 The Big (Bayesian) Picture Learning objectives: Learn to think like a Bayesian. Explore the foundations of a Bayesian data analysis and how they contrast with the frequentist alternative Learn a little bit about the history of the Bayesian philosophy "],["thinking-like-a-bayesian-14.html", "1.1 Thinking like a Bayesian 1/4", " 1.1 Thinking like a Bayesian 1/4 DiagrammeR::grViz(&quot; digraph thinking_bayesian{ # node statement node [shape = oval] a [label = &#39;Prior&#39;]; b [label = &#39;Data&#39;]; c [label = &#39;Posterior&#39;]; d [label = &#39;New data&#39;]; e [label = &#39;Posterior&#39;]; f [label = &#39;New data&#39;] g [style = invisible ] # edge statement a -&gt; c b -&gt; c c -&gt; e d -&gt; e f-&gt; g [style = dashed] e-&gt; g [style = dashed] }&quot;) Figure 1.1: A Bayesian knowledge-building diagram In Bayesian analysis, the prior represents what you know before seeing the data. The posterior then represents what you know having seen the data. Both Bayesian and frequentist share a common goal: learn from data about the world around. Both use data to fit nodels, make predictions and evaluate hypothesis "],["quiz-time.html", "1.2 Quiz time!", " 1.2 Quiz time! 4-5: frequentist 6-8: a bit of both 9-12: Bayesian TODO link to script and data in repo "],["thinking-like-a-bayesian-24.html", "1.3 Thinking like a Bayesian 2/4", " 1.3 Thinking like a Bayesian 2/4 1.3.1 Interpreting probability: Bayesian philosophy: relative plausibility of an event Frequentist philosophy: long-run relative frequency of a repeatable event "],["thinking-like-a-bayesian-34.html", "1.4 Thinking like a Bayesian 3/4", " 1.4 Thinking like a Bayesian 3/4 1.4.1 Bayesian balancing act Two claims: Zuofo claims he can predict the outcome of coin flip Kavya claims she can distinguish between natural and artificial sweeteners If both succeed with a 10/10 sucess rate what can we conclude from this? The frequentist approach will discard prior knowledge (it is harder to predict coin flip that having a sensitive palate to sweeteners) and the Bayesian want to use this prior knowledge. -&gt; How can we balance Prior and Data? "],["thinking-like-a-bayesian-44.html", "1.5 Thinking like a Bayesian 4/4", " 1.5 Thinking like a Bayesian 4/4 1.5.1 Asking question What’s the chance that I actually have the disease (a)? Versus I do not have the disease, What’s the chance that I would have gotten this positive test results (b)? # building data disease &lt;- c(rep(&quot;disease&quot;, 4), rep(&quot;no disease&quot;, 96)) a &lt;- &quot;test positive&quot; ; b &lt;- &quot;test negative&quot; test &lt;- c(rep(a, 3), b, rep(a, 9), rep(b, 87)) disease_status &lt;- data.frame(disease, test) # contingency table contingency_disease &lt;- table(disease_status) contingency_disease &lt;- addmargins(contingency_disease) knitr::kable(contingency_disease ) test negative test positive Sum disease 1 3 4 no disease 87 9 96 Sum 88 12 100 (a): 3 / 12 (b): 9 / 96 Analogy between (b) and p-value: it is more natural to study the uncertainty of a yet-unproven hypothesis than the uncertainty of data we have already observed.(authors’opinion) "],["quick-history-lesson.html", "1.6 Quick history lesson", " 1.6 Quick history lesson From stigmatized to being used in modeling COVID-19 rates. Why? advances in computing departure from tradition (what people learn is what people use) reevaluation of subjectivity : frequentist is also subjective and subjectivity is not any more a dirty word. "],["look-ahead.html", "1.7 Look ahead", " 1.7 Look ahead 1.7.1 4 units Bayesian foundations: 5 chapters Focus: models &amp; distributions (conjugate family) Posterior simulations &amp; analysis: 3 chapters Focus: when conjugate is not an option: MCMC then posterior analysis Bayesian regression &amp; classification Focus: extending unit 1 reponse variable (Y) with predictor variables (X) Hierarchical Bayesian models Focus: expanding unit 3 to accomodate and harness grouped data. "],["summary.html", "1.8 Summary", " 1.8 Summary Posterior knowledge &lt;- balancing information from data and prior knowledge More “waves”of data -&gt; refine knowledge (less effect of prior) With more and more data, two analysts will converge on the same posterior knowledge "],["resources-mentioned.html", "1.9 Resources mentioned", " 1.9 Resources mentioned This is a list of resources mentioned in the first meeting! 1.9.1 Other Bayesian books: Richard McElreath * book: https://xcelab.net/rm/statistical-rethinking/ * vidéo: https://github.com/rmcelreath/stat_rethinking_2022 The “puppy” book by John K. Kruschke : https://sites.google.com/site/doingbayesiandataanalysis/ Introduction to Bayesian Thinking, Clyde, Centinkaya-Rundel et al similar level to our book Bayesian Data Analysis, Andrew Gelman more precise (and mathematical) Intro to Bayes Theorem, Wrath of Math, video Clear explanation of the meaning of given in statements like probability of A given B. $ P(A | B) $ 1.9.2 Drawing DAG (Directed Acyclic Graph) Pen and paper DiagrammeR: for drawing diagram, uses Graphviz or mermaid Dagitty: for causal diagrams 1.9.3 Podcast Learning Bayesian Statistics ep. 42 With Mine Dogucu "],["meeting-videos.html", "1.10 Meeting Videos", " 1.10 Meeting Videos 1.10.1 Cohort 1 Meeting chat log 00:06:01 Olivier: hello ! 00:06:47 Olivier: various links : https://r4ds.github.io/bookclub-bayes_rules/ 00:06:55 Olivier: https://docs.google.com/spreadsheets/d/18IDSOU2bfkD55kOB18qCB7Idbpiyp4_9qeWjkvE-Syc/edit#gid=0 00:09:44 Olivier: Letś wait that everyone configure zoom :P 00:10:18 Gabby Palomo: I didn&#39;t see if anyone else signed up for this cohort. I imagine more people did, right? 00:10:46 Olivier: I do not know the number of participant 00:10:52 Olivier: I will have to ask 00:11:08 Will: Well hopefully. I&#39;m assuming for fellow Brits there are lots people celebrating the jubilee. 00:11:59 Gabby Palomo: ah that&#39;s true!! 00:12:10 erik.aalto@tocaboca.com: I’m not hearing anything, but I could hear recording in progress when I joined.. 00:12:24 Olivier: do you hear me ? 00:12:27 Gabby Palomo: There are 85 people in the slack channel so will see. 00:12:42 erik.aalto@tocaboca.com: Nope, cant hear anything:/ 00:13:15 Will: Yes I think I can hear Erik 00:13:45 erik.aalto@tocaboca.com: Darn, can’t hear anything…this is weird 00:13:57 Olivier: we hear you at least 00:14:03 erik.aalto@tocaboca.com: I hear the zoom notifs…like ”recording in progress” 00:15:52 Olivier: it is fine 00:16:13 Olivier: is it better 00:17:24 Olivier: is it good now ? 00:17:41 Olivier: i restaart it 00:19:02 Olivier: working or not ? 00:19:20 Ronald Legere: Not yet… there is a audio test thing in the audio settings menu 00:19:48 Olivier: good name 00:56:58 Ronald Legere: Can you link those podcasts to slack? Or here ;) 01:06:31 Olivier Leroy: DiagrammeR 1.10.2 Cohort 2 1.10.3 Cohort 3 Meeting chat log 00:18:42 Mary EMERAGHI: Hello Everyone... So, I will drop a brief on myself here since I am in a different timezone. I am a beginner with little or no knowledge of this subject save that I have knowledge of Basic Statistics and would want to advance deeper to use it for my plant breeding work on Rice and Cereals 00:19:05 Mary EMERAGHI: My Name though is Mary Emeraghi from Nigeria 00:19:16 Mary EMERAGHI: Currently in Cote d&#39;Ivoire 00:20:59 Mary EMERAGHI: Could I get the full details of these books especially on Theoretical knowledge to help me 00:21:01 Mary EMERAGHI: ? 00:21:47 Mary EMERAGHI: thanks Gabby 00:21:54 Mary EMERAGHI: By who please? 00:21:55 Gabby Palomo: Bayesian Models: A statistical primer for ecologists; Hobbs and Hooten 00:22:21 Gabby Palomo: Doing Bayesian Data Analysis: A tutorial with R, JAGS, and Stan. John Kruschke. 00:22:56 Mary EMERAGHI: much appreciated 00:47:48 Mary EMERAGHI: no 00:47:55 Mary EMERAGHI: sorry 01:05:06 Oluwafemi Oyedele: Thank you !!! "],["bayes-rule.html", "Chapter 2 Bayes’ Rule", " Chapter 2 Bayes’ Rule Learning objectives: Explore foundational probability tools conditional probability: Probability of A given B \\(P(A|B)\\) joint probability: Probability of A and B occuring \\(P(A \\cap B)\\) marginal probability: Probability of an event \\(P(A)\\) Law of Total Probability: If a probability of an event is unknown it can be calculated using the known probability of other related event Conduct first formal Bayesian analysis Practice your Bayesian grammar Prior Likelihood Normalizing constant Simulate Bayesian models sample() sample_n() rbinon() "],["building-a-bayesian-model-for-events.html", "2.1 Building a Bayesian model for events", " 2.1 Building a Bayesian model for events First Data set ?? fake_news Figure 2.1: Bayesian knowledge-building diagram for wether or not the article is fake Two variables: - fake vs real - ! or not 2.1.1 Workflow: Prior probability model A model for interpreting the data Posterior probability model Prior probability model: \\[ P(FakeNew = 0.4 ) \\quad and \\quad P(Real = 0.6) \\] \\[ P(B = 0.4 ) \\quad and \\quad P(B^c = 0.6) \\] Here \\(P(FakeNew)\\) : prior probability of an article to be a fake news. A valid probability model must: account for all events; assign probabilities for each event; sum to one. Conditional probability &amp; likelihood \\(P(ExClam)\\) : probability that an article contains an exclamation mark in his title We know that if an article is fake news : 26.67% that the title contains ! and if it is not fake this is just 2.22%. \\[ P(Exclam|FakeNew) = 0.2667 \\quad and \\quad P(Exclam|Real = 0.0222) \\] This is a conditional probability. Conditional probability helps us know if B gives us an insight in A. If it does not provide any information, it means that events A and B are independent (\\(P(A|B) = P(A)\\)). "],["normalizing-constant.html", "2.2 Normalizing constant", " 2.2 Normalizing constant \\(P(Exclam|FakeNew) = 0.2667 \\quad and \\quad P(Exclam|Real) = 0.0222)\\) are our likelihood, when we know A (!) we know that getting B (Fake news) is more likely. It is different that our prior probability. Then we need can calculate the joint probability (probability of observing A nd B for example), of each options (here it is half of them): \\[ P(Exclam \\cap FakeNew) = P(Exclam|FakeNew) P (Fakenew) = 0.2667 *0.4 = 0.1067 \\] \\[ P(PasExclam \\cap FakeNew ) = (1 - P(Exclam|FakeNew)) * P(FakeNew)) = (1 - 0.2667) * 0.4 = 0.2993 \\] Here \\(P(B)\\) is the marginal probability of B B &lt;- c(0.1067, 0.2933, 0.4) Bc &lt;- c(0.0133, 0.5867, 0.6) Total &lt;- c(0.12, 0.88, 1) joint_p &lt;- data.frame(B, Bc, Total, row.names = c(&quot;A&quot;, &quot;Ac&quot;, &quot;Total&quot;)) knitr::kable(joint_p) B Bc Total A 0.1067 0.0133 0.12 Ac 0.2933 0.5867 0.88 Total 0.4000 0.6000 1.00 \\(P(Exclam)\\) is our normalizing constant. Ok but we want \\(P(FakeNew|exlam)\\) ie \\(P(B|A)\\) \\[ P(FakeNew|exclam) = \\frac{P(exclam \\cap FakeNew)}{P(Exclam)} = \\frac{P(FakeNew)L(FakeNew|Exclam)}{P(Exclam)} \\] \\[ posterior = \\frac{prior . likelihood}{normalizing \\quad constant} = \\frac{0.4 * 0.2667}{0.12} = 0.889 \\] "],["posterior-simulation.html", "2.3 Posterior simulation", " 2.3 Posterior simulation This was a model. Now we will use a simulation! library(dplyr) library(ggplot2) set.seed(84735) # Define possible articles article &lt;- data.frame(type = c(&quot;real&quot;, &quot;fake&quot;)) # Define the prior model prior &lt;- c(0.6, 0.4) article_sim &lt;- dplyr::sample_n(article, size = 10000, weight = prior, replace = TRUE) # dats model article_sim &lt;- article_sim %&gt;% mutate(data_model = case_when(type == &quot;fake&quot; ~ 0.2667, type == &quot;real&quot; ~ 0.0222)) # Simulate exclamation point usage data &lt;- c(&quot;NoExclam&quot;, &quot;Exclam&quot;) set.seed(3) # Rbase simplier ? article_sim &lt;- article_sim %&gt;% group_by(1:n()) %&gt;% mutate(usage = sample(data, size = 1, prob = c(1 - data_model, data_model))) ggplot(article_sim, aes(x = type)) + geom_bar() + facet_wrap(~ usage) "],["example-pop-vs-soda-vs-coke.html", "2.4 Example Pop vs Soda vs Coke", " 2.4 Example Pop vs Soda vs Coke Expend TRUE/FALSE example with one with categories. "],["building-a-bayesian-model-for-random-variables-1n.html", "2.5 Building a Bayesian model for random variables (1/n)", " 2.5 Building a Bayesian model for random variables (1/n) 2.5.1 First step prior \\(\\pi\\) : skill of Kasparov relative to Deep Blue (random variable) Prior model of \\(\\pi\\): pi &lt;- c(0.2, 0.5, 0.8, &quot;total&quot;) # pmf : probability mass functions pmf &lt;- c(0.1, 0.25, 0.65, 1) prior_pi &lt;- data.frame(pi, pmf) knitr::kable(t(prior_pi)) pi 0.2 0.5 0.8 total pmf 0.10 0.25 0.65 1.00 "],["building-a-bayesian-model-for-random-variables-1n-1.html", "2.6 Building a Bayesian model for random variables (1/n)", " 2.6 Building a Bayesian model for random variables (1/n) 2.6.1 Binomial data model Y is the number of games (on 6 games) that Kasparov wins. Y our random variable: {0, 1, …., 6} , depends on \\(\\pi\\) \\[f(y|\\pi) = P (Y = y|\\pi ) \\] \\(y\\) : any possible outcone If we assume games are independents (no effect on each other) and \\(\\pi\\) is fixed we can use the Binomial model. Y is the number of successes in a fixed number of trials (\\(n\\)) \\[ Y|\\pi \\sim Bin(n, \\pi) \\] \\[ f(y|\\pi) = \\begin{pmatrix} 6 \\\\y \\end{pmatrix} \\pi^y(1 - \\pi)^{6 - y} \\quad for \\quad y \\in \\begin{Bmatrix} 0, 1, 2, 3, 4, 5, 6 \\end{Bmatrix} \\] We can use the prior for \\(\\pi\\) and all \\(y\\) to calculate each probabilities. "],["building-a-bayesian-model-for-random-variables-1n-2.html", "2.7 Building a Bayesian model for random variables (1/n)", " 2.7 Building a Bayesian model for random variables (1/n) 2.7.1 Binomial likelihood function Kasparov only won one of six games. This is our data with \\(L(\\pi|y = 1)\\). We can calculate it for each \\(\\pi\\) value. What is more likely is that \\(pi\\) was 0.2. 2.7.2 Probability mass functions vs likelihood functions When \\(\\pi\\) is known the conditional pmf allows us to compare the probabilities of different possible value of data Y (y1, y2 ..) occuring with \\(pi\\) when Y = y is known the likelihood function allows us to to compare the relative values of \\(\\pi\\) (\\(\\pi_1, \\pi_2, etc ..\\)) 2.7.3 Normalizing constant Total probability that Kasparov would win Y = 1 game across all possible win probability of \\(\\pi\\) We apply the Law of Total Probability (the sum of all likelihood for each value of \\(\\pi\\) by the prior probailities of these \\(\\pi\\) values) \\[ f(y = 1) = L(\\pi = 0.2 | y = 1) f(\\pi = 0.2 ) + L(\\pi = 0.5 | y = 1) f(\\pi = 0.5 ) + L(\\pi = 0.8 | y = 1) f(\\pi = 0.8 ) +\\] \\[ f( y = 1) \\simeq 0.3932 * 0.1 + 0.0938 * 0.25 + 0.0015 * 0.65 \\simeq 0.0637 \\] 2.7.4 Posterior probability model We have the prior, the likelihod and the normalizing constant -&gt; Bayes Rules! \\[ posterior = \\frac{prior . likelihood}{normalizing \\quad constant} \\quad for \\in \\begin{Bmatrix} 0.2, 0 5, 0.8 \\end{Bmatrix} \\] 2.7.5 Posterior shortcut The normalizing constant, is a constant it appears in all posterior calculations. We can work with unnormalizied proabilities or we can divide each unnormalizied probability by the sum of each of them. \\[ posterior \\propto prior * likelihood \\] ## Posterior simulation # Define possible win probabilities chess &lt;- data.frame(pi = c(0.2, 0.5, 0.8)) # Define the prior model prior &lt;- c(0.10, 0.25, 0.65) # Simulate 10000 values of pi from the prior set.seed(84735) chess_sim &lt;- sample_n(chess, size = 10000, weight = prior, replace = TRUE) chess_sim &lt;- chess_sim %&gt;% mutate(y = rbinom(10000, size = 6, prob = pi)) # Focus on simulations with y = 1 win_one &lt;- chess_sim %&gt;% filter(y == 1) # Plot the posterior approximation ggplot(win_one, aes(x = pi)) + geom_bar() "],["links-shared-in-the-second-meeting.html", "2.8 Links shared in the second meeting", " 2.8 Links shared in the second meeting Bayesian probability for babies! (with cookies) : https://raw.githubusercontent.com/epimath/epid-814-materials/master/Lectures/BayesianEstimation.pdf Author: Marisa Eisenberg "],["meeting-videos-1.html", "2.9 Meeting Videos", " 2.9 Meeting Videos 2.9.1 Cohort 1 Meeting chat log 00:11:44 erik.aalto@tocaboca.com: Hello, sorry for joining late, happy to see you again 😄 00:36:06 Brendan Lam: https://www.youtube.com/watch?v=HZGCoVF3YvM 00:37:26 Erik: we’ll utilize the following likelihood function notation &lt;poorly formatted paste&gt; 00:37:41 Erik: sorry for how the formatting above went… 00:42:42 Lisa: to add to brendan&#39;s resource, here is a slide deck using cookies as an example: https://github.com/epimath/epid-814-materials/blob/master/Lectures/BayesianEstimation.pdf 01:02:00 Federica Gazzelloni: thanks 01:02:34 Federica Gazzelloni: I’d like to go back to the L(..|..) 01:02:35 Gabby Palomo: It was clear Olivier. Don’t worry!! 01:03:07 Federica Gazzelloni: just to understand how it works and what is the difference 01:03:43 Erik: Need to jump out! Thanks for today. 01:04:15 Lisa: I need to get back to work too. thank you for today! 01:04:58 Federica Gazzelloni: thanks 01:05:03 Federica Gazzelloni: I’ll check that 2.9.2 Cohort 2 2.9.3 Cohort 3 "],["the-beta-binomial-bayesian-model.html", "Chapter 3 The Beta-Binomial Bayesian Model", " Chapter 3 The Beta-Binomial Bayesian Model Learning objectives: We will learn how to interpret and tune a continuous Beta prior model to reflect your prior information about \\(\\pi\\) We will learn how to interpret and communicate features of prior and posterior models using properties such as mean, mode, and variance Construct the fundamental Beta-Binomial model for proportion \\(\\pi\\) To prepare for this chapter, note that we’ll be using three Greek letters throughout our analysis: \\(\\pi\\) = pi, \\(\\alpha\\) = alpha, and \\(\\beta\\) = beta. Further load the packages below. library(bayesrules) library(tidyverse) "],["what-is-a-beta-binomial-model-for.html", "3.1 What is a Beta Binomial model for ?", " 3.1 What is a Beta Binomial model for ? It is a model we use when we want to look at something with a proportion. Examples of use: The proportion of people that use public transit, the proportion of trains that are delayed, the proportion of people that prefer cats to dogs, and so on. The Beta-Binomial model provides the tools we need to study the proportion of interest,\\(\\pi\\), in each of these settings. "],["the-beta-prior-model.html", "3.2 The Beta Prior Model", " 3.2 The Beta Prior Model The first model we are going to construct is based on a scenario where you are a campaign manager for Michelle for president campaign in the state of Minnesota. So far we have conducted 30 opinion pools. Michelle’s support is generally around 45% but has been as low as 35% and as high as 55%. This is going to form the basis for our prior. "],["are-we-good-so-far.html", "3.3 Are we good so far ?", " 3.3 Are we good so far ? "],["how-has-the-model-changed-from-last-week.html", "3.4 How has the model changed from last week ?", " 3.4 How has the model changed from last week ? The example of Kasparov’s probability of beating Deep Blue at chess was a discrete example. In that case, we greatly over-simplified reality to fit within the framework of introductory Bayesian models. Mainly, we assumed that \\(\\pi\\) could only be 0.2, 0.5, or 0.8, the corresponding chances of which were defined by a discrete probability model. However, in the reality of Michelle’s election support and Kasparov’s chess skill, \\(\\pi\\) can be any value between 0 and 1. We can reflect this reality and conduct a more nuanced Bayesian analysis by constructing a continuous prior probability model. So …. Probability density functions for continuous models rather than Probability mass functions for discrete models "],["what-quality-does-the-probability-density-function-have.html", "3.5 What quality does the probability density function have ?", " 3.5 What quality does the probability density function have ? The proportion has to be greater than or equal to zero The area under the curve sums to 1 The area under the curve between a and b sums to the probability of pie being in that range. "],["tuning-the-beta-prior.html", "3.6 Tuning the Beta Prior", " 3.6 Tuning the Beta Prior This is a process of trial and error Plot the Beta(45,55) prior plot_beta(45,55) "],["the-binomial-data-model-and-likelihood.html", "3.7 The Binomial Data Model and Likelihood", " 3.7 The Binomial Data Model and Likelihood This is where we gather some new data by conducting an opinion poll. on this occasion we ask 50 people who are they supporting and 30 of them are supporting Michelle. Binomial Data Model and Likelihood The likelihood function, \\(L(\\pi\\)|Y =30), of Michelle’s election support \\(\\pi\\) given the observed poll in which Y = 30 of n=50 polled Minnesotans supported her. The vertical lines represent the likelihood evaluated at \\(\\pi\\) in {0.1,0.2,….0.9}. "],["beta-posterior-model.html", "3.8 Beta Posterior Model", " 3.8 Beta Posterior Model We now have two pieces of our Bayesian model in place – the Beta prior model for Michelle’s support \\(\\pi\\) and the Binomial model for the dependence of polling data Y on \\(\\pi\\): Y|\\(\\pi\\) ~ Bin(50,\\(\\pi\\)) \\(\\pi\\) ~ Beta(45,55) The prior and data, as captured by the likelihood, don’t completely agree. Constructed from old polls, the prior is a bit more pessimistic about Michelle’s election support than the data obtained from the latest poll. Yet both insights are valuable to our analysis. Just as much as we shouldn’t ignore the new poll in favor of the old, we also shouldn’t throw out our bank of prior information in favor of the newest thing (also great life advice). Thinking like Bayesians, we can construct a posterior model of \\(\\pi\\) which combines the information from the prior with that from the data. The Posterior model of \\(\\pi\\) along with the (scaled) likelihood function of \\(\\pi\\) given the new poll results in which Y = 30 of n = 50 polled Minnesotans support Michelle. What are we missing from this plot ? Which plot reflects the correct posterior model of Michelle’s election support \\(\\pi\\)? "],["plot-of-the-beta-posterior-model.html", "3.9 Plot of the Beta Posterior Model", " 3.9 Plot of the Beta Posterior Model plot_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50) The beta posterior model is B The prior pdf, scaled likelihood function, and posterior pdf of Michelle’s election support \\(\\pi\\). "],["effects-of-new-data.html", "3.10 Effects of New Data ?", " 3.10 Effects of New Data ? summarize_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50) ## model alpha beta mean mode var sd ## 1 prior 45 55 0.45 0.4489796 0.002450495 0.04950248 ## 2 posterior 75 75 0.50 0.5000000 0.001655629 0.04068942 A comparison illuminates the polling data’s influence on the posterior model. Mainly, after observing the poll in which 30 of 50 people supported Michelle, the expected value of her underlying support \\(\\pi\\) nudged up from approximately 45% to 50%. "],["simulating-the-beta-binomial.html", "3.11 Simulating the Beta-Binomial", " 3.11 Simulating the Beta-Binomial Here we are going to simulate the posterior model of Michelle’s support \\(\\pi\\). We bigin by simulating 10,000 values of \\(\\pi\\) from Beta(45,55) prior using rbeta() and, subsequently, a potential Bin(50,\\(\\pi\\)) poll result Y from each \\(\\pi\\) using rbinom() The resulting 10,000 pairs of \\(\\pi\\) and Y values are shown below. In general, the greater Michelle’s support, the better her poll results tend to be. Further, the highlighted pairs illustrate that the eventual observed poll result, Y=30 of 50 polled voters supported Michelle, would most likely arise if her underlying support \\(\\pi\\) were somewhere in the range from 0.4 to 0.6. michelle_sim &lt;- data.frame(pi = rbeta(10000,45,55)) |&gt; mutate(y=rbinom(10000,size=50,prob=pi)) ggplot(data=michelle_sim,aes(x=pi, y=y))+ geom_point(aes(color=(y==30)),size=0.1) Separate out from the simulation the results that match your new data where 30 out of 50 are supporting Michelle. # Keep the simulated pairs that match your data michelle_posterior &lt;- michelle_sim |&gt; filter(y==30) head(michelle_posterior) ## pi y ## 1 0.4735200 30 ## 2 0.5556420 30 ## 3 0.5286516 30 ## 4 0.5051052 30 ## 5 0.4723425 30 ## 6 0.5225939 30 "],["what-does-this-show.html", "3.12 What does this show ?", " 3.12 What does this show ? ggplot(data=michelle_posterior,aes(x=pi))+ geom_density() michelle_posterior |&gt; summarise(mean(pi),sd(pi)) ## mean(pi) sd(pi) ## 1 0.4993024 0.03969542 # We can also check the number of data points it is based on nrow(michelle_posterior) ## [1] 207 "],["milgrams-behavior-study-of-obedience.html", "3.13 Milgram’s behavior study of obedience", " 3.13 Milgram’s behavior study of obedience This is the famous study where the subjects were asked to deliver an electric shock to an actor under the ruse of a study on the effect of punishment on memory. In reality what was being tested was obedience to authority and the conflict with personal conscience. "],["what-do-you-think-the-prior-beliefs-were.html", "3.14 What do you think the prior beliefs were ?", " 3.14 What do you think the prior beliefs were ? Given the Beta (1,10) prior model, what does that reveal about the psychologist’s prior understanding of \\(\\pi\\) They don’t have an informed opinion They are fairly certain that a large proportion of people will do what authority tells them. They are fairly certain that only a small proportion of people will do what authority tells them. "],["let-plot-them-to-find-out.html", "3.15 Let plot them to find out", " 3.15 Let plot them to find out # Beta(1,10) prior plot_beta(alpha = 1,beta = 10) "],["so-what-actually-happened.html", "3.16 So what actually happened ?", " 3.16 So what actually happened ? Obedience to authority won out The prior was not supported by the evidence The data collected showed that 26 out of 40 participants inflicted the maximum electric shock. "],["what-conclusions-can-we-draw.html", "3.17 What conclusions can we draw ?", " 3.17 What conclusions can we draw ? Prior: though they started out with an understanding that fewer than ~25% of people would inflict the most service shock. Data: given the strong counter evidence in the study area. Posterior: they now understand this figure to be somewhere between ~30% and ~70%. "],["lets-plot-the-prior-likelihood-and-posterior.html", "3.18 Let’s plot the prior, likelihood and posterior", " 3.18 Let’s plot the prior, likelihood and posterior plot_beta_binomial(alpha = 1, beta = 10, y = 26, n = 40) "],["summary-1.html", "3.19 Summary", " 3.19 Summary We built a Beta-Binomial model for unknown proportion anywhere between 0 and 1 Like every Bayesian analysis Beta-Binomial models have four common elements. Prior model Data model Likelihood function Posterior model "],["meeting-videos-2.html", "3.20 Meeting Videos", " 3.20 Meeting Videos 3.20.1 Cohort 1 Meeting chat log 00:10:55 Kasia Ozga: host disabled whitboard so we will not try it 😛 00:30:25 Will Parbury: 3 Blue 1 Brown: Binomial distributions | Probabilities of probabilities, part 1 https://www.youtube.com/watch?v=8idr1WZ1A7Q Serrano.Academy: The Beta Distribution in 12 minutes! https://www.youtube.com/watch?v=juF3r12nM5A PsychEd: Milgram’s Obedience Experiment https://www.youtube.com/watch?v=cBDkJ-Nc3Ig 00:30:38 Federica Gazzelloni: thanks 00:35:29 Federica Gazzelloni: you can watch the fist two videos of advancedR cohort6 book club for how to make the notes 00:36:32 Federica Gazzelloni: https://www.youtube.com/playlist?list=PL3x6DOfs2NGjnCxGKeDNJUfPpRFI2hJjv 00:36:58 Lisa: thanks! 00:38:21 Federica Gazzelloni: to make the notes have a look at the first and the third videos 00:38:42 Federica Gazzelloni: just the begin 00:40:39 Kasia Ozga: v 00:40:52 Kasia Ozga: https://ben18785.shinyapps.io/distribution-zoo/ 00:44:06 Kasia Ozga: mean is alpha / (alpha +alpha) 00:44:25 Kasia Ozga: 0,4 = 1/alpha 3.20.2 Cohort 2 3.20.3 Cohort 3 Meeting chat log 00:58:08 Matthew Efoli: hello everyone 00:58:19 Matthew Efoli: my name is Matthew 01:01:34 Matthew Efoli: I am in the slack "],["balance-and-sequentiality-in-bayesian-analyses.html", "Chapter 4 Balance and Sequentiality in Bayesian Analyses", " Chapter 4 Balance and Sequentiality in Bayesian Analyses Learning objectives: Explore the balanced influence of the prior and data on the posterior. You will see how our choice of prior model, the features of our data, and the delicate balance between them can impact the posterior model. Perform sequential Bayesian analysis. You will explore one of the coolest features of Bayesian analysis: how a posterior model evolves as it’s updated with new data. "],["introductory-example.html", "4.1 Introductory Example", " 4.1 Introductory Example First, let’s remember: Three friends (feminist, clueless, optimist) discuss the proportion (\\(\\pi\\)) of recent movies that pass the Bechdel test (representation of women in film). Which Beta prior corresponds to each of the friends? The three friends agree to review a sample of n recet movies and record Y, the number of movies that pass the Bechdel test. Y is the number of ‘successes’ in a fixed number of independent trials. \\[Y \\sim {Bin}(n,\\,\\pi)\\] \\[\\pi \\sim {Beta}(\\alpha,\\,\\beta)\\] Each analyst has their own unique posterior model of \\(\\pi\\). \\[\\pi|(Y = y) \\sim {Beta}(\\alpha + y,\\,\\beta + n -y)\\] "],["different-priors-different-posteriors.html", "4.2 Different priors, different posteriors", " 4.2 Different priors, different posteriors The more certain the prior information, the smaller the prior variability [Optimist friend]. Informative prior An informative prior reflects specific information about the unknown variable with high certainty, i.e., low variability. The more vague the prior information, the greater the prior variability [Clueless friend]. Vague prior A vague or diffuse prior reflects little specific information about the unknown variable. A flat prior, which assigns equal prior plausibility to all possible values of the variable, is a special case. How will their different priors influence the posterior conclusions of the friends? To answer this question, they collected some data! Review 20 recent movies picked at random. html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #gcfsdknrgj .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #gcfsdknrgj .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gcfsdknrgj .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #gcfsdknrgj .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #gcfsdknrgj .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gcfsdknrgj .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gcfsdknrgj .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: bold; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #gcfsdknrgj .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: bold; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #gcfsdknrgj .gt_column_spanner_outer:first-child { padding-left: 0; } #gcfsdknrgj .gt_column_spanner_outer:last-child { padding-right: 0; } #gcfsdknrgj .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #gcfsdknrgj .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #gcfsdknrgj .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #gcfsdknrgj .gt_from_md > :first-child { margin-top: 0; } #gcfsdknrgj .gt_from_md > :last-child { margin-bottom: 0; } #gcfsdknrgj .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #gcfsdknrgj .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #gcfsdknrgj .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #gcfsdknrgj .gt_row_group_first td { border-top-width: 2px; } #gcfsdknrgj .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gcfsdknrgj .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #gcfsdknrgj .gt_first_summary_row.thick { border-top-width: 2px; } #gcfsdknrgj .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gcfsdknrgj .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gcfsdknrgj .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #gcfsdknrgj .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #gcfsdknrgj .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gcfsdknrgj .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gcfsdknrgj .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #gcfsdknrgj .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gcfsdknrgj .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #gcfsdknrgj .gt_left { text-align: left; } #gcfsdknrgj .gt_center { text-align: center; } #gcfsdknrgj .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #gcfsdknrgj .gt_font_normal { font-weight: normal; } #gcfsdknrgj .gt_font_bold { font-weight: bold; } #gcfsdknrgj .gt_font_italic { font-style: italic; } #gcfsdknrgj .gt_super { font-size: 65%; } #gcfsdknrgj .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #gcfsdknrgj .gt_asterisk { font-size: 100%; vertical-align: 0; } #gcfsdknrgj .gt_indent_1 { text-indent: 5px; } #gcfsdknrgj .gt_indent_2 { text-indent: 10px; } #gcfsdknrgj .gt_indent_3 { text-indent: 15px; } #gcfsdknrgj .gt_indent_4 { text-indent: 20px; } #gcfsdknrgj .gt_indent_5 { text-indent: 25px; } year title binary 2005 King Kong FAIL 1983 Flashdance PASS 2013 The Purge FAIL bechdel_20 %&gt;% tabyl(binary) %&gt;% adorn_totals(&quot;row&quot;) %&gt;% gt() %&gt;% tab_options(column_labels.font.weight = &#39;bold&#39;) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #rguqtkfzie .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #rguqtkfzie .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rguqtkfzie .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #rguqtkfzie .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #rguqtkfzie .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rguqtkfzie .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rguqtkfzie .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: bold; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #rguqtkfzie .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: bold; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #rguqtkfzie .gt_column_spanner_outer:first-child { padding-left: 0; } #rguqtkfzie .gt_column_spanner_outer:last-child { padding-right: 0; } #rguqtkfzie .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #rguqtkfzie .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #rguqtkfzie .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #rguqtkfzie .gt_from_md > :first-child { margin-top: 0; } #rguqtkfzie .gt_from_md > :last-child { margin-bottom: 0; } #rguqtkfzie .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #rguqtkfzie .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #rguqtkfzie .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #rguqtkfzie .gt_row_group_first td { border-top-width: 2px; } #rguqtkfzie .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rguqtkfzie .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #rguqtkfzie .gt_first_summary_row.thick { border-top-width: 2px; } #rguqtkfzie .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rguqtkfzie .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rguqtkfzie .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #rguqtkfzie .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #rguqtkfzie .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rguqtkfzie .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rguqtkfzie .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #rguqtkfzie .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rguqtkfzie .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #rguqtkfzie .gt_left { text-align: left; } #rguqtkfzie .gt_center { text-align: center; } #rguqtkfzie .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #rguqtkfzie .gt_font_normal { font-weight: normal; } #rguqtkfzie .gt_font_bold { font-weight: bold; } #rguqtkfzie .gt_font_italic { font-style: italic; } #rguqtkfzie .gt_super { font-size: 65%; } #rguqtkfzie .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #rguqtkfzie .gt_asterisk { font-size: 100%; vertical-align: 0; } #rguqtkfzie .gt_indent_1 { text-indent: 5px; } #rguqtkfzie .gt_indent_2 { text-indent: 10px; } #rguqtkfzie .gt_indent_3 { text-indent: 15px; } #rguqtkfzie .gt_indent_4 { text-indent: 20px; } #rguqtkfzie .gt_indent_5 { text-indent: 25px; } binary n percent FAIL 11 0.55 PASS 9 0.45 Total 20 1.00 "],["different-data-different-posteriors.html", "4.3 Different data, different posteriors", " 4.3 Different data, different posteriors Now let’s vary sample sizes. The larger the sample size n, the more ‘insistent’ the likelihood function. We see that the more insistent the likelihood, the more influence the data holds over the posterior. "],["striking-a-balance-between-the-prior-and-data.html", "4.4 Striking a balance between the prior and data", " 4.4 Striking a balance between the prior and data The grid of plots illustrates the balance that the posterior model strikes between the prior and data. Each row corresponds to a unique prior model and each column to a unique set of data. The likelihood’s insistence and, correspondingly, the data’s influence over the posterior increase with sample size n. The influence of our prior understanding diminishes as we amass new data. Further, the rate at which the posterior balance tips in favor of the data depends upon the prior. Naturally, the more informative the prior, the greater its influence on the posterior. KEY UNDERSTANDING: no matter the strength of and discrepancies among their prior understanding of \\(\\pi\\), three analysts will come to a common posterior understanding in light of strong data. # Plot the Beta-Binomial model plot_beta_binomial(alpha = 5, beta =11, y = 50, n = 99) # Obtain numerical summaries of the Beta-Binomial model summarize_beta_binomial(alpha = 5, beta = 11, y = 50, n = 99) %&gt;% gt() %&gt;% fmt_number(columns = c(mean, mode, var, sd), decimals = 2) %&gt;% tab_options(column_labels.font.weight = &#39;bold&#39;) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #fmdhbywmqa .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #fmdhbywmqa .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fmdhbywmqa .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #fmdhbywmqa .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #fmdhbywmqa .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fmdhbywmqa .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fmdhbywmqa .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: bold; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #fmdhbywmqa .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: bold; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #fmdhbywmqa .gt_column_spanner_outer:first-child { padding-left: 0; } #fmdhbywmqa .gt_column_spanner_outer:last-child { padding-right: 0; } #fmdhbywmqa .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #fmdhbywmqa .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #fmdhbywmqa .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #fmdhbywmqa .gt_from_md > :first-child { margin-top: 0; } #fmdhbywmqa .gt_from_md > :last-child { margin-bottom: 0; } #fmdhbywmqa .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #fmdhbywmqa .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #fmdhbywmqa .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #fmdhbywmqa .gt_row_group_first td { border-top-width: 2px; } #fmdhbywmqa .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fmdhbywmqa .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #fmdhbywmqa .gt_first_summary_row.thick { border-top-width: 2px; } #fmdhbywmqa .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fmdhbywmqa .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fmdhbywmqa .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #fmdhbywmqa .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #fmdhbywmqa .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fmdhbywmqa .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fmdhbywmqa .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #fmdhbywmqa .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fmdhbywmqa .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #fmdhbywmqa .gt_left { text-align: left; } #fmdhbywmqa .gt_center { text-align: center; } #fmdhbywmqa .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #fmdhbywmqa .gt_font_normal { font-weight: normal; } #fmdhbywmqa .gt_font_bold { font-weight: bold; } #fmdhbywmqa .gt_font_italic { font-style: italic; } #fmdhbywmqa .gt_super { font-size: 65%; } #fmdhbywmqa .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #fmdhbywmqa .gt_asterisk { font-size: 100%; vertical-align: 0; } #fmdhbywmqa .gt_indent_1 { text-indent: 5px; } #fmdhbywmqa .gt_indent_2 { text-indent: 10px; } #fmdhbywmqa .gt_indent_3 { text-indent: 15px; } #fmdhbywmqa .gt_indent_4 { text-indent: 20px; } #fmdhbywmqa .gt_indent_5 { text-indent: 25px; } model alpha beta mean mode var sd prior 5 11 0.31 0.29 0.01 0.11 posterior 55 60 0.48 0.48 0.00 0.05 4.4.1 Connecting concepts to theory Mathemagical! "],["sequential-analysis-evolving-with-data.html", "4.5 Sequential analysis: evolving with data", " 4.5 Sequential analysis: evolving with data We examined the increasing influence of the data and diminishing influence of the prior on the posterior as more and more data come in. Consider the nuances of this concept. The phrase “as more and more data come in” evokes the idea that data collection, and thus the evolution in our posterior understanding, happens incrementally. Sequential Bayesian analysis (aka Bayesian learning) In a sequential Bayesian analysis, a posterior model is updated incrementally as more data come in. With each new piece of data, the previous posterior model reflecting our understanding prior to observing this data becomes the new prior model. Data order invariant. The final posterior only depends upon the cumulative data. "],["meeting-videos-3.html", "4.6 Meeting Videos", " 4.6 Meeting Videos 4.6.1 Cohort 1 Meeting chat log 00:14:08 Brendan Lam: eventually! 4.6.2 Cohort 2 "],["conjugate-families.html", "Chapter 5 Conjugate Families", " Chapter 5 Conjugate Families Learning objectives: Practice building Bayesian models Familiarize yourself with conjugacy "],["greek-letters.html", "5.1 Greek letters", " 5.1 Greek letters \\(\\lambda\\) = lambda \\(\\mu\\) = mu \\(\\sigma\\) = sigma \\(\\tau\\) = tau \\(\\theta\\) = theta This our last chapter on Bayesian foundations! "],["revisiting-choice-of-prior.html", "5.2 Revisiting choice of prior", " 5.2 Revisiting choice of prior Flexibility Computational ease: posterior easy to build Interpretability 5.2.1 Reminder the Beta-Binomial Model: Prior: \\(Beta (\\alpha, \\beta)\\) Data model: \\(Y = y \\quad for \\quad Bin(n, \\pi)\\) Posterior: \\(Beta(\\alpha + y, \\beta = n - y)\\) "],["joy.html", "5.3 Joy!", " 5.3 Joy! (yes I know it was the other way!) "],["gamma-poisson-conjugate-family-18.html", "5.4 Gamma-Poisson conjugate family 1/8", " 5.4 Gamma-Poisson conjugate family 1/8 We are going to do a model to estimate the number of fraud risk phone call: 5.4.1 Prior: rate \\(\\tau \\approx\\) 5 number of phone call / day can range from 2-7 "],["gamma-poisson-conjugate-family-28.html", "5.5 Gamma-Poisson conjugate family 2/8", " 5.5 Gamma-Poisson conjugate family 2/8 5.5.1 Poisson data model: \\(Y =\\) number of independant event that occur in a fixed ammount of time \\[Y|y \\sim Pois(\\tau) \\] Probability mass function: \\[ f(y|Y) = \\frac{\\tau^ye^-\\tau}{y!} \\quad for y \\in \\{0, 1, 2, ...\\} \\] (sum to 1) \\[E(Y|\\tau) = Var(Y|\\tau) = \\tau \\] "],["gamma-poisson-conjugate-family-38.html", "5.6 Gamma-Poisson conjugate family 3/8", " 5.6 Gamma-Poisson conjugate family 3/8 5.6.1 Poisson pmfs with different \\(\\tau\\) "],["gamma-poisson-conjugate-family-48.html", "5.7 Gamma-Poisson conjugate family 4/8", " 5.7 Gamma-Poisson conjugate family 4/8 5.7.1 Joint probability mass function We have pmf for each day but if we want for \\(n\\) day we need to use joint probably mass function. (product of every pmf) \\[L(\\tau|\\overrightarrow{y}) = \\frac{\\tau^{\\sum y_i e^{-n\\tau}}}{\\prod_{i=n}^{n} y!} \\propto e^{-n\\tau} \\tau^{\\sum y_i}\\] We just need : \\(n\\) and \\(\\sum y_i\\) "],["gamma-poisson-conjugate-family-58.html", "5.8 Gamma-Poisson conjugate family 5/8", " 5.8 Gamma-Poisson conjugate family 5/8 5.8.1 Potential priors? \\(\\tau\\) is postif and continuous We have 3 probability models : Gamma : \\(f(\\tau) \\propto \\tau^{s-1} e^{-r\\tau}\\) Weibull : \\(f(\\tau) \\propto \\tau^{s-1} e^{(-r\\tau)^s}\\) F : \\(f(\\tau) \\propto \\tau^{s/2 - 1} (1 + \\tau) ^ -s\\) Quiz! Which one ? "],["gamma-poisson-conjugate-family-68.html", "5.9 Gamma-Poisson conjugate family 6/8", " 5.9 Gamma-Poisson conjugate family 6/8 5.9.1 Gamma prior : Gamma and Exponential models \\(\\tau\\) continuous random variable but can only take + value \\[\\tau \\sim Gamma(s, r)\\] Probability density functions: \\[f(\\tau) = \\frac{r^s}{\\Gamma (s)} \\tau^{s - 1} e^{-r\\tau} \\quad for \\quad \\tau &gt; 0 \\] \\[ E(\\tau) = \\frac{s}{r} ; Mode(\\tau) = \\frac{s - 1}{r} \\quad for \\quad s \\geq 1; Var(\\tau) = \\frac{s}{r^2} \\] When s = 1 -&gt; Exponenial model = Gamma(1,r) \\[\\tau \\sim Exp(r)\\] "],["gamma-poisson-conjugate-family-6n.html", "5.10 Gamma-Poisson conjugate family 6/n", " 5.10 Gamma-Poisson conjugate family 6/n 5.10.1 Quiz! Gamma when s &gt; r ? Gamme when s &lt; r ? More variability in Gamma(20, 20) or Gamma(20, 100) ? dashed = modes solid = means "],["gamma-poisson-conjugate-family-78.html", "5.11 Gamma-Poisson conjugate family 7/8", " 5.11 Gamma-Poisson conjugate family 7/8 5.11.1 Applications! \\[ E(\\tau) = \\frac{s}{r} \\approx 5\\] -&gt; we need \\(s = 5r\\) Trial and error: bayesrules::plot_gamma(shape = 10, rate = 2) Yeahhhh! we have a Prior! "],["gamma-poisson-conjugate-family-88.html", "5.12 Gamma-Poisson conjugate family 8/8", " 5.12 Gamma-Poisson conjugate family 8/8 5.12.1 Gamma-Poisson conjugacy Now need a posterior! \\[ \\tau|\\overrightarrow{y} \\sim Gamma(s + \\sum y_i, r +n) \\] We have: Gamma(10,2) and as data: \\(\\overrightarrow{y} = (6 + 2 + 2+ 1 )\\) , \\(n = 4\\) \\[\\sum_{i = 1}^{4} = 6 + 2 + 2 + 1 =11\\] \\[\\overline{y} = \\frac{\\sum_{i = 1}^{4}}{4} = 2.75\\] \\[L(\\tau|\\overrightarrow{y}) = \\frac{\\tau^ye^{-n\\tau}}{y!}\\] \\[L(\\tau|\\overrightarrow{y}) = \\frac{\\tau^{11}e^{-4\\tau}}{6!2!2!1!} \\propto \\tau^{11}e^{-4\\tau}\\] bayesrules::plot_poisson_likelihood(y = c(6, 2, 2, 1), lambda_upper_bound = 10) We have prior, data, likelihood -&gt; posterior \\[Gamma(10, 2) \\longrightarrow Gamma(s + \\sum y_i, r +n)\\] \\[\\tau|\\overrightarrow{y} \\sim Gamma(21, 6) \\] bayesrules::plot_gamma_poisson(shape = 10, rate = 2, sum_y = 11, n = 4) "],["normal-normal-conjugate-family.html", "5.13 Normal-Normal conjugate family", " 5.13 Normal-Normal conjugate family TODO … Kitten Love GIFfrom Kitten GIFs "],["why-no-simulation-in-this-chapter.html", "5.14 Why no simulation in this chapter?", " 5.14 Why no simulation in this chapter? Hard to do! We moved from sample size 1 -&gt; \\(n\\) "],["critiques-of-conjugate-family.html", "5.15 Critiques of conjugate family", " 5.15 Critiques of conjugate family less flexible in selection the prior some does not allow flat prior "],["summary-2.html", "5.16 Summary", " 5.16 Summary conjugate priors are easy to compute/derive, interpretable Beta-Binomial: data Y is the number of successes in a set of \\(n\\) trials Gamma-Poisson: Y is a count with no upper limit Normal-Normal: Y is continuous "],["slide-1.html", "5.17 SLIDE 1", " 5.17 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-4.html", "5.18 Meeting Videos", " 5.18 Meeting Videos 5.18.1 Cohort 1 5.18.2 Cohort 2 5.18.3 Cohort 3 Meeting chat log LOG ## Loading required package: StanHeaders ## rstan (Version 2.21.7, GitRev: 2e1f913d3ca3) ## For execution on a local, multicore CPU with excess RAM we recommend calling ## options(mc.cores = parallel::detectCores()). ## To avoid recompilation of unchanged Stan programs, we recommend calling ## rstan_options(auto_write = TRUE) ## ## Attaching package: &#39;rstan&#39; ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract ## This is bayesplot version 1.9.0 ## - Online documentation and vignettes at mc-stan.org/bayesplot ## - bayesplot theme set to bayesplot::theme_default() ## * Does _not_ affect other ggplot2 plots ## * See ?bayesplot_theme_set for details on theme setting "],["approximating-the-posterior.html", "Chapter 6 Approximating the Posterior", " Chapter 6 Approximating the Posterior Learning objectives: Implement and examine the limitations of using grid approximation to simulate a posterior model. Explore the MCMC posterior simulation using R Learn several Markov chain diagnostics for examining the quality of an MCMC posterior simulation. N.B. We will learn more about how MCMC works in the next chapter! "],["motivation-for-approximations.html", "6.1 Motivation for approximations", " 6.1 Motivation for approximations Remember we are trying to compute the posterior distribution: \\[ f\\left(\\theta | y \\right) = \\frac{f(\\theta)L(\\theta | y)}{f(y)} \\] In previous examples (conjugate priors) we were able to do this analytically Numerator - no issue, we specify these distributions. Denominator - Can be difficult or intractable to compute the denominator f(y) ! \\[ f(y) = \\int_{\\theta_1}\\int_{\\theta_2} ... \\int_{\\theta_k}f(\\theta)L(\\theta | y) d\\theta_k ... d\\theta_1 d\\theta_2 \\] Solution? Aapproximate the posterior via simulation! "],["grid-approximaiton.html", "6.2 Grid Approximaiton", " 6.2 Grid Approximaiton Discretized approximation of the posterior. Method of producing samples: Define a grid of possible values of the parameters \\(\\theta\\), Evaluate the numerator at each possible value Obtain a discrete approximation of \\(f(\\theta|y)\\) by normalizing the results (i.e. divide by the sum!) Randomly sample the grid values using the probabilities determined in step 3. "],["beta-binomial-example-grid.html", "6.3 Beta Binomial Example (Grid)", " 6.3 Beta Binomial Example (Grid) \\[ Y|\\pi \\sim Bin(10,\\pi)\\\\ \\pi \\sim Beta(2,2)\\] Observe \\(Y=9\\) successes. # Step 1: Define grid grid_data &lt;- data.frame(pi_grid = seq(from = 0, to = 1, length = 100)) # Step 2: Evaluate numerator grid_data &lt;- grid_data %&gt;% mutate(prior = dbeta(pi_grid, 2, 2), likelihood = dbinom(9, 10, pi_grid)) %&gt;% mutate( unnormalized = prior*likelihood) # Step 3: Normalize! grid_data &lt;- grid_data %&gt;% mutate(posterior = unnormalized/sum(unnormalized)) ggplot(grid_data, aes(x = pi_grid, y = posterior)) + geom_point() + geom_segment(aes(x = pi_grid, xend = pi_grid, y = 0, yend = posterior)) Sample from this posterior (Step 4) set.seed(84735) #BAYES post_sample &lt;- sample_n(grid_data, size = 10000, weight = posterior, replace = TRUE) ggplot(post_sample, aes(x = pi_grid)) + geom_histogram(aes(y = ..density..), color = &quot;white&quot;, binwidth = 0.05) + stat_function(fun = dbeta, args = list(11, 3)) + lims(x = c(0, 1)) ## Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(density)` instead. ## Warning: Removed 2 rows containing missing values (`geom_bar()`). We can compute any summary statistics from the samples (or from the grid posterior itself!) "],["mcmc.html", "6.4 MCMC", " 6.4 MCMC Curse of dimensionality -&gt; Grid approximation is limited to cases with only a few parameters. Markov Chain Monte Carlo produces a Markov chain of samples to approximate posterior. Markov Chain: \\(\\theta^{(i+1)} \\sim f(\\theta^{(i+1)} | \\theta^{(i)}, y)\\) Monte Carlo: Random samples from chain. Samples are not directly from the posterior and are not independent! More on how it works in next chapter. But we can just jump in with rstan "],["beta-binomial-mcmc.html", "6.5 Beta-Binomial (MCMC)", " 6.5 Beta-Binomial (MCMC) # define model in stan language bb_model &lt;- &quot; data { int&lt;lower = 0, upper = 10&gt; Y; } parameters { real&lt;lower = 0, upper = 1&gt; pi; } model { Y ~ binomial(10, pi); pi ~ beta(2, 2); } &quot; # use stan to simulate posterior bb_sim &lt;- stan(model_code = bb_model, data = list(Y = 9), chains = 4, iter = 5000*2, seed = 84735) Uses 4 chains and 10000 samples of which 1/2 are discarded by default for burn-in Result is a stanfit object, which can be used to extract the samples # for examining using view chains &lt;- as.data.frame(as.array(bb_sim, pars = &quot;pi&quot;)) # look at a zoom in of the sample trace mcmc_trace(bb_sim, pars = &quot;pi&quot;, window = c(50,100),size =0.1) Trace shows the samples exploring the parameter space but also illustrates non-zero autocorrelation. We can also plot the resulting distribution of samples (book shows that this is close to beta-binomial expected) mcmc_dens(bb_sim, pars = &quot;pi&quot;) + yaxis_text(TRUE) + ylab(&quot;density&quot;) "],["markov-chain-diagnostics.html", "6.6 Markov chain diagnostics", " 6.6 Markov chain diagnostics Primary tools: Trace plots Effective sample size Autocorrelation R-hat With trace plots, look for good mixing and compare parallel chains. Effective sample size takes into account the correlation between samples. (best if &gt; 10% of actual samples) neff_ratio(bb_sim, pars = c(&quot;pi&quot;)) ## [1] 0.3472187 Autocorrelation measures the correlation between pairs of Markov chain values that are Lag “steps” apart mcmc_acf(bb_sim, pars = &quot;pi&quot;) R-hat is the ratio of the variability between chains to the variability within chains. R-hat &gt; 1.05 is cause for concern. rhat(bb_sim, pars=&quot;pi&quot;) ## [1] 1.000393 "],["summary-3.html", "6.7 Summary", " 6.7 Summary More sophisticated Bayesian models often require approximations Learned about two methods: Grid Approximation (straightforward but limited) MCMC (more flexible) Learned some MCMC diagnostics Next chapter, MCMC under the hood "],["meeting-videos-5.html", "6.8 Meeting Videos", " 6.8 Meeting Videos 6.8.1 Cohort 1 6.8.2 Cohort 2 Meeting chat log 00:11:00 Ron: 6.12 through 6.18 6.8.3 Cohort 3 Meeting chat log LOG "],["mcmc-under-the-hood.html", "Chapter 7 MCMC under the Hood", " Chapter 7 MCMC under the Hood Learning objectives: Conceptual understanding of how Markov chain algorithms work Explore Metropolis-Hastings algorithm Implement it with the Normal-Normal "],["the-big-idea-12.html", "7.1 The big idea 1/2", " 7.1 The big idea 1/2 We are going to use a Normal-Normal model: \\[ Y|\\mu \\sim Norm(\\mu, 0.75^2)\\] \\[ \\mu \\sim Norm(0, 1^2) \\] Observed outcome 6.25: \\[ \\mu|(Y = 6.25) \\sim Norm(4, 0.6^2)\\] Main idea: chain need to spend more time around \\(\\mu\\) value. Remember \\(\\mu^{i+1}\\) is dependant of \\(\\mu^{i}\\). How are we going to visit every part of the posterior dustribution: step 1 : propose a random location \\(\\mu&#39;\\) (I prefer \\(\\mu_{proposal}\\)) for the nex stop step 2 : Decide whether to: go to the proposed location: \\(\\mu_{proposal} = \\mu^{i+1}\\) stay at the current location: \\(\\mu = \\mu^{i+1}\\) Monte Carlo algorithm: step 1 propose location: draw \\(\\mu\\) from posterior model with \\(pdf \\quad f(\\mu|y)\\) step 2 : Go there "],["the-big-idea-22.html", "7.2 The big idea 2/2", " 7.2 The big idea 2/2 But we are using MCMC to approximate this pdf (so we can’t sample it). For we are going to use two tricks: We do know that \\(f(u|y = 6.25) \\propto f(\\mu)L(u|y = 6.25)\\) For step 1 we can use an other model or distribution to generate proposals \\[ \\mu_{proposal}|\\mu \\sim Unif(\\mu - w, \\mu, + w) \\] with pdf: \\[ q(\\mu&#39;|\\mu) = \\frac{1}{2 w}\\] This give us a way for doing step1! "],["the-metropolis-hastings-algorithm.html", "7.3 The Metropolis-Hastings algorithm", " 7.3 The Metropolis-Hastings algorithm step 1: ok : \\(q(\\mu_{proposal}|\\mu)\\) step 2: we are going to calculate an acceptance probability: \\[\\alpha = \\{1, \\frac{f(\\mu_{proposal}) L(\\mu_{proposal}|y) q(\\mu|\\mu_{proposal})}{f(\\mu)L(\\mu|y) q(\\mu_{proposal|\\mu})} \\}\\] Because the Uniform proposal model is symmetric: \\[ q(\\mu_{proposal}|\\mu) = q(\\mu|\\mu_{proposal})\\] Then after multiplying by \\(f(y)\\) we have now: \\[ \\alpha = min\\{1, \\frac{f(\\mu_{proposal}|y)}{f(\\mu|y)} \\} \\] This ration is equivalent to the unnormalized posterior. Two scnearios: Scenario 1: \\(f(\\mu_{proposal}|y) \\geq f(\\mu|y)\\) -&gt; \\(\\alpha = 1\\) we are moving Scenario 2: $f(_{proposal}|y) &lt; f(|y) $ then we move according to the probability \\(\\alpha\\) one_mh_iteration &lt;- function(w, current){ # STEP 1: Propose the next chain location proposal &lt;- runif(1, min = current - w, max = current + w) # STEP 2: Decide whether or not to go there proposal_plaus &lt;- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75) current_plaus &lt;- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75) alpha &lt;- min(1, proposal_plaus / current_plaus) next_stop &lt;- sample(c(proposal, current), size = 1, prob = c(alpha, 1-alpha)) # Return the results return(data.frame(proposal, alpha, next_stop)) } set.seed(8) one_mh_iteration(w = 1, current = 3) ## proposal alpha next_stop ## 1 2.93259 0.8240205 2.93259 "],["implementing-the-metropolis-hastings.html", "7.4 Implementing the Metropolis-Hastings", " 7.4 Implementing the Metropolis-Hastings mh_tour &lt;- function(N, w){ # 1. Start the chain at location 3 current &lt;- 3 # 2. Initialize the simulation mu &lt;- rep(0, N) # 3. Simulate N Markov chain stops for(i in 1:N){ # Simulate one iteration sim &lt;- one_mh_iteration(w = w, current = current) # Record next location mu[i] &lt;- sim$next_stop # Reset the current location current &lt;- sim$next_stop } # 4. Return the chain locations return(data.frame(iteration = c(1:N), mu)) } library(ggplot2) set.seed(84735) mh_simulation_1 &lt;- mh_tour(N = 5000, w = 1) ggplot(mh_simulation_1, aes(x = iteration, y = mu)) + geom_line() ggplot(mh_simulation_1, aes(x = mu)) + geom_histogram(aes(y = ..density..), color = &quot;white&quot;, bins = 20) + stat_function(fun = dnorm, args = list(4,0.6), color = &quot;blue&quot;) ## Tuning the Metropolis-Hastings algorithm 7.4.1 Quiz! w = 0.01 or w = 100, or w = 1 "],["a-beta-binomial-example.html", "7.5 A Beta-Binomial example", " 7.5 A Beta-Binomial example 1 success in 2 trials \\[ Y|\\pi = bin(2, \\pi) \\] \\[ \\pi = Beta(2,3) \\] We are still playing “pretend” We are moving for step 1 to an Uniform to a Beta model because we want \\(\\pi\\) to be [0,1]. And we will draw every step from this Beta model. -&gt; change in step 1 \\[\\alpha = min \\{1, \\frac{f(\\pi_{proposal}|y)q(\\pi)}{f(\\pi|y) q(\\pi_{proposal})} \\} \\] one_iteration &lt;- function(a, b, current){ # STEP 1: Propose the next chain location proposal &lt;- rbeta(1, a, b) # STEP 2: Decide whether or not to go there proposal_plaus &lt;- dbeta(proposal, 2, 3) * dbinom(1, 2, proposal) proposal_q &lt;- dbeta(proposal, a, b) # &lt;- new current_plaus &lt;- dbeta(current, 2, 3) * dbinom(1, 2, current) current_q &lt;- dbeta(current, a, b) # &lt;- new alpha &lt;- min(1, proposal_plaus / current_plaus * current_q / proposal_q) next_stop &lt;- sample(c(proposal, current), size = 1, prob = c(alpha, 1-alpha)) return(data.frame(proposal, alpha, next_stop)) } betabin_tour &lt;- function(N, a, b){ # 1. Start the chain at location 0.5 current &lt;- 0.5 # 2. Initialize the simulation pi &lt;- rep(0, N) # 3. Simulate N Markov chain stops for(i in 1:N){ # Simulate one iteration sim &lt;- one_iteration(a = a, b = b, current = current) # Record next location pi[i] &lt;- sim$next_stop # Reset the current location current &lt;- sim$next_stop } # 4. Return the chain locations return(data.frame(iteration = c(1:N), pi)) } "],["why-the-algorithm-works.html", "7.6 Why the algorithm works", " 7.6 Why the algorithm works If the algorithm works : \\[\\frac{\\mu \\rightarrow \\mu_{proposa}}{\\mu_{proposal} \\rightarrow \\mu} = \\frac{ f(\\mu_{proposal}|y)}{f(\\mu|y)}\\] "],["chapter-summary.html", "7.7 Chapter summary", " 7.7 Chapter summary Step 1 Propose a new chain location by drawing from a proposal pdf which is perhaps dependent upon the current location Determine whether accept the proposal: depends on how favorable its posterior plausibility is relative to the posterior plausibility of the current location "],["meeting-videos-6.html", "7.8 Meeting Videos", " 7.8 Meeting Videos 7.8.1 Cohort 1 Meeting chat log 00:00:12 Federica Gazzelloni: Hello! 00:58:29 olivier leroy: while (count_accept &lt; M) { count_draw &lt;- count_draw + 1 un_runif &lt;- runif(1) k &lt;- rbinom(prob = un_runif, size = 10, n = 1) if(k == kobs) { count_accept &lt;- count_accept + 1 post[count_accept] &lt;- un_runif } } 01:04:14 olivier leroy: https://www.youtube.com/watch?v=Qqz5AJjyugM&amp;list=PLDcUM9US4XdMROZ57-OIRtIK0aOynbgZN&amp;index=8&amp;pp=sAQB 7.8.2 Cohort 2 7.8.3 Cohort 3 Meeting chat log LOG "],["posterior-inference-prediction.html", "Chapter 8 Posterior Inference &amp; Prediction", " Chapter 8 Posterior Inference &amp; Prediction Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-1.html", "8.1 SLIDE 1", " 8.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-7.html", "8.2 Meeting Videos", " 8.2 Meeting Videos 8.2.1 Cohort 1 Meeting chat log 00:00:57 Olivier’s iPhone: I am on mobile phone now, I will turn camera later! 01:08:30 Brendan Lam: Learning Bayesian Stats Podcast: https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5jYXB0aXZhdGUuZm0vbGVhcm5iYXllc3N0YXRzLw?sa=X&amp;ved=0CAMQ4aUDahcKEwj45ff4opz5AhUAAAAAHQAAAAAQAQ&amp;hl=en-CA 01:14:30 Brendan Lam: https://errorstatistics.com/ 8.2.2 Cohort 2 8.2.3 Cohort 3 Meeting chat log LOG "],["simple-normal-regression.html", "Chapter 9 Simple Normal Regression", " Chapter 9 Simple Normal Regression Learning objectives: Building simple linear regression model Understand Bayesian approach to regression Interpret appropriate prior models Simulate posterior model of the regression parameters Utilize simulation result to build posterior understanding of relationship between response (\\(Y\\)) and predictors (\\(X\\)) build posterior predictive models of \\(Y\\) "],["begining-of-unit-3.html", "9.1 Begining of Unit 3!", " 9.1 Begining of Unit 3! Congratulations on our progress! "],["new-terms.html", "9.2 New terms", " 9.2 New terms \\(Y \\rightarrow\\) Response variable \\(X_{1}, X_{2}, ..., X_{p} \\rightarrow\\) Predictors We want to analyze quantitative response : Regression We want to analyze categorical response: Classification In this chapter we will focus on the Normal regression model. Our toy example will come from a bike sharing service. We will try to understand the demand for it service. We want a model of the number of rides/day. Poisson model is not valid here because we do not have an equal mean and variance. Instead we are going to go with a normal model: \\[Y_{i}|\\mu, \\sigma \\overset{ind}{\\sim} N(\\mu, \\sigma^2) \\] \\[ \\mu \\sim N(\\theta, \\tau^2) \\] \\[ \\sigma \\sim some \\; prior \\; model \\] Can’t we do better with a predictor? Here it will be the temperature in Fahrenheit. "],["building-the-regression-model.html", "9.3 Building the regression model", " 9.3 Building the regression model 9.3.1 Data model We will have n data pairs of bike ridership (\\(Y\\)) and temperature (\\(X\\)) : \\[\\{(Y_{1}, X_{1}), (Y_{2}, X_{2}), ..., (Y_{n}, X_{n}) \\}\\] Here prior knowledge suggest positive linear relationship between ridership and temperature: the warmer it is, the more likely people are using bike share service. We are now moving away from the global mean (\\(\\mu\\)) to local mean (\\(\\mu_{i}\\), where \\(i\\) is one day). If the relationship is linear : \\[ \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] \\(\\beta_{0}\\) is the intercept coefficent but it is hard to interpret (would you rent bike when it is 0 degree F?) \\(\\beta_{1}\\) is the Temperature coefficient it indicates the typical change in ridership for every one unit increase in temperature. In case we have just one quantitative predictor it is called the slope. We can plunk this assumption in our model : \\[ Y_{i}| \\beta_{0}, \\beta_{1}, \\sigma \\overset{ind}{\\sim} N(\\mu_{i}, \\sigma^2) \\; with \\quad \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] As you can see \\(\\sigma\\) is now about variability from the local mean 9.3.1.1 Normal regression assumptions Structure of the data: accounting for \\(X\\), \\(Y\\) for one day is independent of an other day Structure of the relationship: Y can be written as a linear function of predictor X : \\(\\mu = \\beta_{0} + \\beta_{1}X\\) Structure of the variability: at any value of X, Y will vary normaly around \\(\\mu\\) with a consistent standard deviation \\(\\sigma\\) 9.3.2 Specifying the priors 9.3.2.1 Quiz! What are our parameters ? Results \\[\\beta_{0}, \\beta_{1}, \\sigma\\] First assumption our parameters are independent \\[ \\beta_{0} \\sim N(m_{0}, s^2_{0} ) \\] \\[ \\beta_{1} \\sim N(m_{1}, s^2_{1} ) \\] \\(m_{0}, m_{1}, s_{0}, s_{1}\\) are parameters of parameters so they are : hyperparameters \\[\\sigma \\sim Exp(l)\\] 9.3.3 Putting it all together \\[ Y_{i}| \\beta_{0}, \\beta_{1}, \\sigma \\overset{ind}{\\sim} N(\\mu_{i}, \\sigma^2) \\; with \\quad \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] \\[ \\beta_{0} \\sim N(m_{0}, s^2_{0} ) \\] \\[ \\beta_{1} \\sim N(m_{1}, s^2_{1} ) \\] \\[\\sigma \\sim Exp(l)\\] Model building one step at a time ! Y is discrete or continuous \\(\\rightarrow\\) appropriate model for data Rewrite the mean of Y as a function of predictors X (e.g. \\(\\mu = \\beta_0 + \\beta_1 X\\)) Identify unknown parameters in your model Note the values these parameters might take \\(\\rightarrow\\) Identify appropriate priors "],["tuning-prior-models-for-regression-parameters.html", "9.4 Tuning prior models for regression parameters", " 9.4 Tuning prior models for regression parameters An average temperature day (65, 70 degree F) in DC: 3000-7000 riders with around 5000 For every one degree increase you get about +100 riders \\(\\pm\\) 80 At any given Temperature daily ridership vary with a sd of 1250 rides We will work with centered data \\(\\beta_{0} \\rightarrow \\beta_{0c}\\) because : it is easier to interpret and specify in this example this is what rstanarm uses \\[ Y_{i}| \\beta_{0}, \\beta_{1}, \\sigma \\overset{ind}{\\sim} N(\\mu_{i}, \\sigma^2) \\; with \\quad \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] \\[ \\beta_{0c} \\sim N(5000, 1000^2 ) \\tag{a.}\\] \\[ \\beta_{1} \\sim N(100, 40^2 \\tag{b.}) \\] \\[\\sigma \\sim Exp(0.0008). \\tag{c.}\\] The only hard part was using an equation from chapter 5: \\[E(\\sigma) = \\frac{1}{l} = 1250\\] It is good to simulate this prior and see what they look like but we will do that in the part about using default rstanarm priors later. "],["posterior-simulatiion.html", "9.5 Posterior simulatiion", " 9.5 Posterior simulatiion Now we want to update our prior with data to get a posterior simulation! # Load and plot data library(bayesrules);library(ggplot2) data(bikes) ggplot(bikes, aes(x = temp_feel, y = rides)) + geom_point(size = 0.5) + geom_smooth(method = &quot;lm&quot;, se = FALSE) ## `geom_smooth()` using formula = &#39;y ~ x&#39; I am saving you from the triple integrals in the denominator of p 220 and we are jumping directly to MCMC! We are going to use rstanarm : Rstan + arm = applied regression models 9.5.1 Simulation via rstanarm bike_model &lt;- rstanarm::stan_glm( # data information rides ~ temp_feel, # &lt;- formula syntax (as used by lm, glm etc) data = bikes, family = gaussian, # &lt;- we assume normal data # Priors prior_intercept = normal(5000, 1000), # centered intercept prior = normal(100, 40), prior_aux = exponential(0.0008), #notice the aux for auxiliary more after # MCMC information chains = 4, iter = 5000*2, seed = 84735) 9.5.2 Simulation directly with rstan # STEP 1: DEFINE the model stan_bike_model &lt;- &quot; data { int&lt;lower = 0&gt; n; vector[n] Y; vector[n] X; } parameters { real beta0; real beta1; real&lt;lower = 0&gt; sigma; } model { Y ~ normal(beta0 + beta1 * X, sigma); beta0 ~ normal(-2000, 1000); beta1 ~ normal(100, 40); sigma ~ exponential(0.0008); } &quot; # STEP 2: SIMULATE the posterior stan_bike_sim &lt;- rstan::stan(model_code = stan_bike_model, # data is structured a bit differently data = list(n = nrow(bikes), Y = bikes$rides, X = bikes$temp_feel), # same MCMC chains = 4, iter = 5000*2, seed = 84735) The model will return 5000 x nb of chains simulation of our parameters. Rstanarm will change their name: \\(\\beta_{0} \\rightarrow (intercept)\\) (Note that this is \\(\\beta_{0}\\) even though prior is specified for \\(\\beta_{0c}\\)) \\(\\beta_{1} \\rightarrow temp\\_feel\\) But \\(\\sigma\\) stay sigma. We need to check if the simulation went well for that we can? Answer: [X] Check the effective sample size: neff_ratio [X] Compute rhat [X] Examine trace plot [X] Overlay the density plots of each chains "],["interpreting-the-posterior.html", "9.6 Interpreting the posterior", " 9.6 Interpreting the posterior What we have is samples of each of the parameters. # Posterior summary statistics broom.mixed::tidy(bike_model, # it take our output from rstanarm::stan_glm effects = c(&quot;fixed&quot;, &quot;aux&quot;), # fixed is regression coef et aux is auxiliary ie sigma conf.int = TRUE, conf.level = 0.80) # A tibble: 4 x 5 term estimate std.error conf.low conf.high &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) -2194. 362. -2656. -1732. 2 temp_feel 82.2 5.15 75.6 88.8 3 sigma 1281. 40.7 1231. 1336. 4 mean_PPD 3487. 80.4 3385. 3591. Here we can get the posterior median relationship : \\[ -2194.24 + 82.16X \\] If we want a bigger picture: # Store the 4 chains for each parameter in 1 data frame bike_model_df &lt;- as.data.frame(bike_model) # Check it out nrow(bike_model_df) [1] 20000 head(bike_model_df, 3) (Intercept) temp_feel sigma 1 -2657 88.16 1323 2 -2188 83.01 1323 3 -1984 81.54 1363 # and use add_fitted_draws() from tidybayes # 50 simulated model lines bikes %&gt;% tidybayes::add_fitted_draws(bike_model, n = 50) %&gt;% ggplot(aes(x = temp_feel, y = rides)) + geom_line(aes(y = .value, group = .draw), alpha = 0.15) + geom_point(data = bikes, size = 0.05) # I did not evaluate the code here Figure 9.7 9.6.0.1 Quiz! Do we have ample posterior evidence that there’s a positive association between ridership and temperature ? Answer: Visual evidence : 50 or more posterior scenarios that display positive relationship Numerical evidence from CI: 80% CI for \\(\\beta_{1}\\) range from 75.6 to 88.8 Numerical evidence from posterior probability # Tabulate the beta_1 values that exceed 0 bike_model_df %&gt;% mutate(exceeds_0 = temp_feel &gt; 0) %&gt;% tabyl(exceeds_0) # resuly exceeds_0 n percent TRUE 20000 1 "],["posterior-prediction.html", "9.7 Posterior prediction", " 9.7 Posterior prediction 9.7.1 Quiz! Suppose a weather report indicates that tomorrow will be a 75-degree day in D.C. What’s your posterior guess of the number of riders that Capital Bikeshare should anticipate? Answer: One option is \\[ -2194.24 + 82.16 * 75 = 3967.76 \\] But this does not take into account : Sampling variability Posterior variability The posterior predictive model takes into account both kinds of variability. We can approximate this posterior predictive model with our 20 000 samples of parameters. 9.7.2 Building a posterior predictive model # Predict rides for each parameter set in the chain set.seed(84735) predict_75 &lt;- bike_model_df %&gt;% mutate(mu = `(Intercept)` + temp_feel*75, # &lt;- our 75 degree y_new = rnorm(20000, mean = mu, sd = sigma)) # &lt;- sampling var. head(predict_75, 3) (Intercept) temp_feel sigma mu y_new 1 -2657 88.16 1323 3955 4838 2 -2188 83.01 1323 4038 3874 3 -1984 81.54 1363 4132 5196 Interesting point is mu (\\(\\mu\\)) vs. y_new (\\(Y_{new}\\)). # Construct 80% posterior credible intervals predict_75 %&gt;% summarize(lower_mu = quantile(mu, 0.025), upper_mu = quantile(mu, 0.975), lower_new = quantile(y_new, 0.025), upper_new = quantile(y_new, 0.975)) lower_mu upper_mu lower_new upper_new 1 3843 4095 1500 6482 \\(\\mu\\) is average in readership for 75 degree \\(Y_new\\) is for a specific day (with 75 degree) =&gt; More accuracy in predicting an average than an unique point! 9.7.3 Posterior with rstanarm We have done it from “scratch” but we can use rstanarm::posterior_predict() # Simulate a set of predictions set.seed(84735) shortcut_prediction &lt;- posterior_predict(bike_model, newdata = data.frame(temp_feel = 75)) "],["sequential-regression-modeling.html", "9.8 Sequential regression modeling", " 9.8 Sequential regression modeling We can have our data that come in sequences: phase_1 &lt;- bikes[1:30, ] phase_2 &lt;- bikes[1:60, ] phase_3 &lt;- bikes Bayes rules !figure 9.13 "],["using-default-rstanarm-priors.html", "9.9 Using default rstanarm priors", " 9.9 Using default rstanarm priors Authors recommend using the default prior from rstanarm: bike_model_default &lt;- rstanarm::stan_glm( rides ~ temp_feel, data = bikes, family = gaussian, # here very specific prior on sd prior_intercept = normal(5000, 2.5, autoscale = TRUE), # &lt;- see autoscale arg. prior = normal(0, 2.5, autoscale = TRUE), prior_aux = exponential(1, autoscale = TRUE), chains = 4, iter = 5000*2, seed = 84735) prior_summary(bike_model_default) Priors for model &#39;bike_model_default&#39; ------ Intercept (after predictors centered) Specified prior: ~ normal(location = 5000, scale = 2.5) Adjusted prior: ~ normal(location = 5000, scale = 3937) Coefficients Specified prior: ~ normal(location = 0, scale = 2.5) Adjusted prior: ~ normal(location = 0, scale = 351) Auxiliary (sigma) Specified prior: ~ exponential(rate = 1) Adjusted prior: ~ exponential(rate = 0.00064) ------ See help(&#39;prior_summary.stanreg&#39;) for more details It uses weakly informative priors using the scale of the data. Figure 9.1: Fig 9.5 and 9.14 from Bayes Rules! "],["you-are-not-done-yet.html", "9.10 You are not done yet!", " 9.10 You are not done yet! We have learned just enough to be dangerous! Review next chapter on evaluating the model before applying this new tool! "],["summary-4.html", "9.11 Summary", " 9.11 Summary Built a simple Bayesian Normal regression with response and predictor quantitative First example of a case where Markov Chain Monte Carlo simulation was really needed! Used simulated samples to summarize our posterior understanding of the relationship between response and predictor. Used simulated samples for posterior prediction. "],["resources.html", "9.12 Resources:", " 9.12 Resources: Rstanarm vignette "],["meeting-videos-8.html", "9.13 Meeting Videos", " 9.13 Meeting Videos 9.13.1 Cohort 1 9.13.2 Cohort 2 Meeting chat log 00:13:15 RH100398: https://youtu.be/FlC0-3B1ZFk 01:03:17 RH100398: gotta jump on another call. see you next week! 01:03:24 Robert Hilly: Bye Ryan! 9.13.3 Cohort 3 Meeting chat log LOG "],["evaluating-regression-models.html", "Chapter 10 Evaluating Regression Models", " Chapter 10 Evaluating Regression Models Learning objectives: Determine whether a model is fair Determine how wrong a model is Determine our model’s posterior predictive accuracy "],["more-question-to-ask.html", "10.1 More question to ask", " 10.1 More question to ask When we look at the Bayesian model results, it might be important to investigate a bit more about: How was the data collected? By whom and for what purpose was the data collected? How might the results of the analysis, or the data collection itself, impact individuals and society? What biases might be baked into this analysis? (#fig:10.1)Credits: https://godcgo.com/a-bike-friendly-washington-dc/ "],["verifying-normal-regression-assumptions.html", "10.2 Verifying Normal regression assumptions", " 10.2 Verifying Normal regression assumptions Assumption 1: Structure of the data independency Assumption 2: Structure of the relationship linearity Assumption 3 : Structure of the variability normality "],["our-model-case-is-made-of.html", "10.3 Our model-case is made of:", " 10.3 Our model-case is made of: number of Capital Bikeshare rides: \\(Y_{i}\\) temperature on day \\(i\\): \\(X_{i}\\) (#fig:10.2)Credits: dezeen.com Starting from a Regression Model: \\[ Y_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] We look for an approximation of the real mean value: estimate mean value \\[Y_{i} \\approx\\mu_{i}\\] \\[ \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] “…To turn this into a Bayesian model, we must incorporate prior models for each of the unknown regression parameters…(ct.9.1.2)” with this model parameters: \\[ Y_{i}| \\beta_{0}, \\beta_{1}, \\sigma \\overset{ind}{\\sim} N(\\mu_{i}, \\sigma^2) \\; with \\quad \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] we expect some good results as we consider 500 daily observations within the two-year period. The response variable ridership \\(Y\\) is likely to be correlated over time with other features such as temperature \\(X\\). “…today’s ridership likely tells us something about tomorrow’s ridership. Yet much of this correlation, or dependence, can be explained by the time of year and features associated with the time of year…” “…knowing the temperature on two subsequent days may very well “cancel out” the time correlation in their ridership data…” We are tempted to conclude: the temperatures in one location are independent of those in neighboring locations, the temperatures in one month don’t tell us about the next. (#fig:10.3)Assumption1 It’s reasonable to assume that, in light of the temperature \\(X\\), ridership data \\(Y\\) is independent from day to day. We are looking for a centered value of the intercept: \\[ \\beta_{0c} \\sim N(m_{0}, s^2_{0})= N(5000, 1000^2 ) \\tag{a.}\\] \\[ \\beta_{1} \\sim N(m_{1}, s^2_{1}) = N(100, 40^2 \\tag{b.}) \\] \\[ \\sigma\\sim Exp(l) = Exp(0.0008 \\tag{c.}) \\] data(bikes) ## date rides temp_feel ## 1 2011-01-01 654 64.72625 ## 2 2011-01-03 1229 49.04645 ## 3 2011-01-04 1454 51.09098 ## 4 2011-01-05 1518 52.63430 ## 5 2011-01-07 1362 50.79551 ## 6 2011-01-08 891 46.60286 To evaluate assumptions 2 and 3 we conduct a posterior predictive check. Our first look was at the relationship between rides and temperature, and so at the consistency of the distribution. (#fig:10.7)Assumption 2 and 3 Given the combined model assumptions reasonable, the posterior model should be able to simulate ridership data very close to the original 500 rides observations. bike_model &lt;- rstanarm::stan_glm( rides ~ temp_feel, data = bikes, family = gaussian, prior_intercept = normal(5000, 1000), prior = normal(100, 40), prior_aux = exponential(0.0008), chains = 4, iter = 5000*2, seed = 84735, # suppress the output refresh=0) bike_model_df &lt;- as.data.frame(bike_model) first_set &lt;- head(bike_model_df, 1) first_set ## (Intercept) temp_feel sigma ## 1 -2040.536 80.44231 1280.101 beta_0 &lt;- first_set$`(Intercept)` beta_1 &lt;- first_set$temp_feel sigma &lt;- first_set$sigma set.seed(84735) one_simulation &lt;- bikes %&gt;% mutate(mu = beta_0 + beta_1 * temp_feel, simulated_rides = rnorm(500, mean = mu, sd = sigma)) %&gt;% select(temp_feel, rides, simulated_rides) one_simulation%&gt;%head ## temp_feel rides simulated_rides ## 1 64.72625 654 4020.319 ## 2 49.04645 1229 1746.346 ## 3 51.09098 1454 3068.930 ## 4 52.63430 1518 2496.768 ## 5 50.79551 1362 3065.187 ## 6 46.60286 891 3735.023 ggplot(one_simulation, aes(x = simulated_rides)) + geom_density(color = &quot;lightblue&quot;) + geom_density(aes(x = rides), color = &quot;darkblue&quot;)+ labs(title=&quot;One posterior simulated dataset of ridership (light blue)\\nalong with the actual observed ridership data (dark blue).&quot;)+ ggthemes::theme_fivethirtyeight()+ theme(plot.title = element_text(size=10)) "],["posterior-predictive-check.html", "10.4 Posterior predictive check", " 10.4 Posterior predictive check Use the pp_check() function from {bayesplot} package included in the {rstanarm} package. It compares the observed outcome variable y to simulated datasets from the posterior predictive distribution. # Examine 50 of the 20000 simulated samples pp_check(bike_model,nreps = 50) + xlab(&quot;rides&quot;)+ labs(title=&quot;50 datasets of ridership simulated from the posterior (light blue)\\nalongside the actual observed ridership data (dark blue)&quot;) So, in general to check the last two assumptions you should: Assume a different data structure Make a transformation "],["how-accurate-are-the-posterior-predictive-models.html", "10.5 How accurate are the posterior predictive models?", " 10.5 How accurate are the posterior predictive models? Three approaches to evaluating predictive quality Posterior predictive summaries median absolute error (MAE) scaled median absolute error within_50 and within_95 set.seed(84735) prediction_summary(bike_model, data = bikes) ## mae mae_scaled within_50 within_95 ## 1 990.4453 0.7709476 0.438 0.966 set.seed(84735) predict_75 &lt;- bike_model_df %&gt;% mutate(mu = `(Intercept)` + temp_feel*75, y_new = rnorm(20000, mean = mu, sd = sigma)) # Plot the posterior predictive model ggplot(predict_75, aes(x = y_new)) + geom_density()+ geom_vline(aes(xintercept = 6228))+ labs(title=&quot;The posterior predictive model of ridership on October 22, 2012,\\na 75-degree day. The actual Y = 6228 riders observed that day are\\nmarked by the vertical line.&quot;)+ ggthemes::theme_fivethirtyeight()+ theme(plot.title = element_text(size=10)) set.seed(84735) predictions &lt;- posterior_predict(bike_model, newdata = bikes) dim(predictions) ## [1] 20000 500 ppc_intervals(bikes$rides, yrep = predictions, x = bikes$temp_feel, prob = 0.5, prob_outer = 0.95)+ labs(title=&quot;The posterior predictive medians (light blue dots),\\n50% prediction intervals (wide, short blue bars),\\nand 95% prediction intervals (narrow, long blue bars)\\nfor each day in the bikes dataset, along with the corresponding\\nobserved data points (dark blue dots).&quot;) Cross-validation To see how well our model generalizes to new data beyond our original sample, we can estimate these properties using cross-validation techniques. Train the model Test the model set.seed(84735) cv_procedure &lt;- prediction_summary_cv(model = bike_model, data = bikes, k = 10) cv_procedure$folds%&gt;%head ## fold mae mae_scaled within_50 within_95 ## 1 1 989.9688 0.7695714 0.46 0.98 ## 2 2 965.4630 0.7432483 0.42 1.00 ## 3 3 949.6831 0.7292722 0.42 0.98 ## 4 4 1018.8814 0.7911418 0.46 0.98 ## 5 5 1161.6688 0.9091497 0.36 0.96 ## 6 6 937.0211 0.7321570 0.46 0.94 cv_procedure$cv ## mae mae_scaled within_50 within_95 ## 1 1029.1 0.8014163 0.422 0.968 All we want is: (#fig:10.21)Two hypothetical posterior predictive pdfs for Y new, the yet unobserved ridership on a new day. The eventual observed value of y new, is represented by a dashed vertical line Expected log-predictive density (ELPD) ELPD measures the average log posterior predictive pdf, across all possible new data points. The higher the ELPD, the better. Higher ELPDs indicate greater posterior predictive accuracy when using our model to predict new data points. The loo() function in the {rstanarm} package utilizes leave-one-out cross-validation to estimate the ELPD of a given model: model_elpd &lt;- loo(bike_model) model_elpd$estimates ## Estimate SE ## elpd_loo -4289.034410 13.11464 ## p_loo 2.501565 0.16400 ## looic 8578.068821 26.22928 "],["improving-posterior-predictive-accuracy.html", "10.6 Improving posterior predictive accuracy", " 10.6 Improving posterior predictive accuracy Collect more data Use different or more predictors "],["how-good-is-the-mcmc-simulation-vs-how-good-is-the-model.html", "10.7 How good is the MCMC simulation vs how good is the model?", " 10.7 How good is the MCMC simulation vs how good is the model? How well our MCMC simulation approximates the model? Does the model fit? are the assumptions reasonable? is the model fair? does it produce good predictions? "],["extra-resources.html", "10.8 Extra resources:", " 10.8 Extra resources: The Impact of Weather Conditions on Capital Bikeshare Trips "],["meeting-videos-9.html", "10.9 Meeting Videos", " 10.9 Meeting Videos 10.9.1 Cohort 1 10.9.2 Cohort 2 10.9.3 Cohort 3 Meeting chat log LOG "],["extending-the-normal-regression-model.html", "Chapter 11 Extending the Normal Regression Model", " Chapter 11 Extending the Normal Regression Model Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-2.html", "11.1 SLIDE 1", " 11.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-10.html", "11.2 Meeting Videos", " 11.2 Meeting Videos 11.2.1 Cohort 1 Meeting chat log 00:05:50 olivier: need to relaod! 00:06:02 olivier: but yes quarto seems a bit difficukt 00:08:30 Brendan Lam: HI there! 00:08:33 Brendan Lam: I can&#39;t talk right now 00:08:39 Brendan Lam: But I&#39;ll be here 00:09:01 Federica Gazzelloni: Hello! 00:10:12 Brendan Lam: i think we call them internet cafes 00:10:31 olivier: iinternet taxi 00:12:56 Federica Gazzelloni: hope you find it useful 00:26:10 Brendan Lam: I believe u can do hypothesis testing in Bayesian settings, but the notion of Type I and II error rates aren&#39;t the same? 00:26:27 olivier: called bayes factor no ? unsure 00:26:50 Brendan Lam: Yes^ 00:30:30 olivier: temp3pm ~ . = temp3pm = hundity * wind * pressure 00:30:58 olivier: or temp3pm = humidity + wind etc 00:43:36 Brendan Lam: How many book clubs r you in Federica?? 00:44:10 Federica Gazzelloni: http://www.feat.engineering/ 00:44:12 olivier: R-inla 00:45:12 olivier: do4ds 00:46:06 olivier: https://do4ds.com/ 00:47:14 Brendan Lam: Me too 00:51:44 Brendan Lam: Might be my last one! 00:51:53 Brendan Lam: I have meetings at this time when school starts 00:51:58 Brendan Lam: but will try my best! 00:52:05 Brendan Lam: I might!! 00:52:37 Brendan Lam: Thanks everyone! 00:52:47 Erik Aa: thanks everyone 11.2.2 Cohort 2 11.2.3 Cohort 3 Meeting chat log LOG "],["poisson-negative-binomial-regression.html", "Chapter 12 Poisson &amp; Negative Binomial Regression", " Chapter 12 Poisson &amp; Negative Binomial Regression Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-3.html", "12.1 SLIDE 1", " 12.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-11.html", "12.2 Meeting Videos", " 12.2 Meeting Videos 12.2.1 Cohort 1 Meeting chat log 00:13:31 olivier: http://c1.staticflickr.com/8/7199/6867921547_239ce73660.jpg 00:17:00 Will Parbury: https://en.wikipedia.org/wiki/Julia_Child 00:19:52 olivier: 16:9 00:23:18 olivier: I am lagging a b it so I will switch off video 00:27:53 olivier: ln 00:34:40 olivier: r$&gt; exp(-0.03) [1] 0.9704455 00:35:43 olivier: r$&gt; exp(0.03) [1] 1.030455 00:50:38 olivier: c 12.2.2 Cohort 2 Meeting chat log 00:37:44 Ronald Legere: 2016 it was dem too (Minnesota) 00:39:17 Ronald Legere: All models are wrong 00:39:20 Ronald Legere: ;) 12.2.3 Cohort 3 Meeting chat log LOG "],["logistic-regression.html", "Chapter 13 Logistic Regression", " Chapter 13 Logistic Regression Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-4.html", "13.1 SLIDE 1", " 13.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-12.html", "13.2 Meeting Videos", " 13.2 Meeting Videos 13.2.1 Cohort 1 Meeting chat log 00:04:46 olivier: ok, I borrowed &quot;country cookingfrom a redneck kitchen&quot; and oh boy ... Watergate Salad : 1 (18-ounce) can cushed pineapple 1 (3.4 ounce) box pistachio instant pudding mix 1 (8 ounce) container frozen whipped topping 3 cups of mini marshmallow 1 (8 ounce) jar maraschino cherries (the recipe is &quot;put everything in a bowl&quot;) 00:22:57 olivier: mic is bad 00:32:31 Brendan Lam: This is a really interesting problem that the data science community calls imbalanced learning. I need to do more reading, but there are some Bayesian approaches to this issue: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0152700 00:35:21 Erik Aa: nice article Brendan 🙂 00:35:29 Federica Gazzelloni: thanksù1 00:35:35 Federica Gazzelloni: ! 00:35:44 Federica Gazzelloni: 😄 00:36:03 Erik Aa: Here&#39;s something that’s a bit adjacent, focusing on inbalanced samples in political polls https://www.microsoft.com/en-us/research/wp-content/uploads/2016/04/forecasting-with-nonrepresentative-polls.pdf 00:36:39 Brendan Lam: Very cool!^ 00:38:23 Will Parbury: Basically you can change the cut off figure to make the model more or less sensitive 00:40:42 olivier: did not know that ! 00:41:42 Federica Gazzelloni: you are muted 00:43:31 Will Parbury: Well the mike worked last week! 13.2.2 Cohort 2 Meeting chat log 00:00:12 Ron: afk for a moment 00:00:27 Ron: will be back by 9 am start ;) 01:17:47 Robert Hilly: https://www.youtube.com/watch?v=jMMcELbWBCM 13.2.3 Cohort 3 Meeting chat log LOG "],["naive-bayes-classification.html", "Chapter 14 Naive Bayes Classification", " Chapter 14 Naive Bayes Classification Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-5.html", "14.1 SLIDE 1", " 14.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-13.html", "14.2 Meeting Videos", " 14.2 Meeting Videos 14.2.1 Cohort 1 Meeting chat log 00:44:10 defuneste: plant@net 00:44:28 Lisa: https://identify.plantnet.org/ 00:48:49 Brendan Lam: Thanks everyone! 14.2.2 Cohort 2 Meeting chat log LOG 14.2.3 Cohort 3 Meeting chat log LOG "],["hierarchical-models-are-exciting.html", "Chapter 15 Hierarchical Models are Exciting", " Chapter 15 Hierarchical Models are Exciting Welcome to Unit 4 - The final unit ! Hierarchical models expand our toolbox for hierarchical (grouped / pooled) data: a sampled group of schools and data \\(y\\) on multiple individual students within each school a sampled group of labs and data \\(y\\) from multiple individual experiments within each lab a sampled group of people on whom we make multiple individual observations of information \\(y\\) over time. Unit four will explore these techniques in these final chapters: Chapter 15: Introduce the concepts Chapter 16: Hierarchical models without predictors Chapter 17: Normal Hierarchical Models with predictors Chapter 18: Non-Normal Hierarchical Regression Chapter 19: More Layers! Chapter 15 - Learning objectives: Explore the limitations of our current Bayesian modeling toolbox under two extremes, complete pooling and no pooling. Examine the benefits of the partial pooling provided by hierarchical Bayesian models. Focus on the big ideas and leave the details to subsequent chapters. "],["pooled-grouped-data.html", "15.1 Pooled / Grouped data", " 15.1 Pooled / Grouped data Why do we need hierachical models ? We will use the cherry_blossom_sample data: Many runners ran multiple races as they aged GOAL: understand relationship between running time and age. "],["complete-pooling.html", "15.2 Complete Pooling", " 15.2 Complete Pooling Complete pooling just combines all the observations, ignoring which runner they came from No clear trend appears, book performs linear regression and finds slope consistent with zero. This seems strange: dont we get slower as we age? Zoom in on three runners: # Select an example subset examples &lt;- running %&gt;% filter(runner %in% c(&quot;1&quot;, &quot;20&quot;, &quot;22&quot;)) ggplot(examples, aes(x = age, y = net)) + geom_point() + facet_wrap(~ runner) + geom_abline(aes(intercept = 75.2242, slope = 0.2678), color = &quot;blue&quot;) 15.2.1 Drawbacks of complete pooling Violates assumption of independence! Observations within a runner are correlated. Ignores information about individual runners: people age differently! Produce misleading conclusions of the relationship between predictor and response "],["no-pooling.html", "15.3 No pooling", " 15.3 No pooling Treat each runner separately, with a separate fit for each. Multiple fits, deal with each of the 36 runners seperately Example for 3 runners: Seems great at first glance…. However some significant drawbacks: Cannot reliably generalize to groups outside our sample. Assumes one group doesnt contain any information about another, ignores potentially useful information! (For example, do we really think that first runner gets faster with age?) "],["hierarchical-data.html", "15.4 Hierarchical data", " 15.4 Hierarchical data Cherry Blossom data presents a new challenge: Hierachical data. Hierarchical structure - each group is unique but also connected. Common structure: Groups could be schools and observations students within each school Groups could be labs, observations multiple experiments in each lab Groups could be subjects, observations are a series of tests (Exercise 15.3ff) Middle ground between complete and no pooling: Partial pooling. Provides insight into both Within-group variability Between-group variability "],["partial-pooling.html", "15.5 Partial pooling", " 15.5 Partial pooling Example results (we will see how to do this next week) Figure 15.1: Posterior median models of the no pooled (blue), complete pooled (black), and hierarchical (dashed) models of running time vs age for three example runners and you. Note the fit no longer predicts the first runner getting better with age.. information from other runners informed this fit. Also note that partial pooling allows us to make predictions for new groups… like YOU! "],["summary-5.html", "15.6 Summary", " 15.6 Summary We (I hope) motivated the need for hierarchical models. Explored briefly complete pooling, no pooling and partial pooling models. "],["meeting-videos-14.html", "15.7 Meeting Videos", " 15.7 Meeting Videos 15.7.1 Cohort 1 Meeting chat log 00:29:42 Brendan Lam: Hes got a point 00:31:21 Will Parbury: https://en.wikipedia.org/wiki/Shrinkage_(statistics) 00:31:56 Brendan Lam: http://haines-lab.com/post/on-the-equivalency-between-the-lasso-ridge-regression-and-specific-bayesian-priors/ 00:32:03 Brendan Lam: “On the equivalency between frequentist Ridge (and LASSO) regression and hierarchial Bayesian regression&quot; 00:33:45 defuneste: https://docs.google.com/spreadsheets/d/18IDSOU2bfkD55kOB18qCB7Idbpiyp4_9qeWjkvE-Syc/edit#gid=0 00:37:51 Erik Aa: https://www.youtube.com/watch?v=SocRgsf202M 00:38:02 Lisa Lau: “hierarchical Bayesian models actually contain frequentist ridge and LASSO regression as a special case—namely, we can choose a prior distribution across the β weights that gives us a solution that is equivalent to that of the frequentist ridge or LASSO methods! Not only that, but Bayesian regression gives us a full posterior distribution for each parameter, thus circumventing problems with frequentist regularization that require the use of bootstrapping to estimate confidence intervals.” 😯 00:38:17 Erik Aa: wow 00:39:20 Brendan Lam: Good luck! 15.7.2 Cohort 2 Meeting chat log LOG 15.7.3 Cohort 3 Meeting chat log LOG "],["normal-hierarchical-models-without-predictors.html", "Chapter 16 (Normal) Hierarchical Models without Predictors", " Chapter 16 (Normal) Hierarchical Models without Predictors Learning objectives: Build a hierarchical model of variabl \\(Y\\) with no predictors \\(X\\) Simulate and analyze this hierarchical model with rstanarm Utilize hierarchical models for predicting \\(Y\\) "],["data-set.html", "16.1 Data Set!", " 16.1 Data Set! data(spotify, package = &quot;bayesrules&quot;) We are going to use a subset Spotify data set from #TidyTuesday: 44 artists -&gt; 350 songs spotify &lt;- spotify |&gt; select(artist, title, popularity) |&gt; mutate(artist = fct_reorder(artist, popularity, .fun = &#39;mean&#39;)) table(spotify$artist) |&gt; hist(xlab = &quot;Songs/artist&quot;, col = 4) We are going to illustrate the 3 approaches seen in chapter 15: Complete pooling No pooling Partial pooling Btw my top 3 most listening song/group from last week are: Dina Summer - Passion (cover) The Do - Anita No Purrrple cat - stream "],["complete-pooled-model.html", "16.2 Complete pooled model", " 16.2 Complete pooled model Notations: \\(j\\) will indicate artist, \\(j \\in {1, 2 ..., 44}\\) \\(i\\) will indicate song for artist \\(j\\) \\(n_j\\) Number of song we have for artist \\(j\\) Example: Mia X, the first artist in our data set, has 4 songs -&gt; \\(n_1 = 4\\) ggplot(spotify, aes(x = popularity)) + geom_density() Even if the distribution is left skewed we will go with a Normal-Normal complete pooled model \\[Y_{ij}|\\mu,\\sigma \\sim N (\\mu, \\sigma²)\\] \\[\\mu \\sim N(50, 52^2)\\] \\[\\sigma \\sim Exp(0.048)\\] \\(\\mu\\) and \\(\\sigma\\) are global parameter: they do not vary by artist: \\(\\mu\\): global mean popularity \\(\\sigma\\) : global standard deviation in popularity from song to song spotify_complete_pooled &lt;- stan_glm( popularity ~ 1, # trick is here \\mu = beta_0 (intercept) with no X data = spotify, family = gaussian, prior_intercept = normal(50, 2.5, # I do not understand 2.5 autoscale = TRUE), prior_aux = exponential(1, autoscale = TRUE), chains = 4, iter = 5000*2, seed = 84735) complete_summary &lt;- tidy(spotify_complete_pooled, effects = c(&quot;fixed&quot;, &quot;aux&quot;), conf.int = TRUE, conf.level = 0.80) complete_summary ## # A tibble: 3 × 5 ## term estimate std.error conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 58.4 1.10 57.0 59.8 ## 2 sigma 20.7 0.776 19.7 21.7 ## 3 mean_PPD 58.4 1.57 56.4 60.4 16.2.1 Quiz!! 3 artist: Mia X, artist with the lowest mean popularity in our data set Beyoncé, artist with nearly the highest mean popularity in our data set Mohsen Beats, an artist not in out data set Using complete pooled model, what would be the approximate posterior predictive mean for a new song from this 3 artists? artist_means &lt;- spotify |&gt; group_by(artist) |&gt; summarize(count = n(), popularity = mean(popularity)) set.seed(84735) predictions_complete &lt;- posterior_predict(spotify_complete_pooled, newdata = artist_means) ppc_intervals(artist_means$popularity, yrep = predictions_complete, prob_outer = 0.80) + ggplot2::scale_x_continuous(labels = artist_means$artist, breaks = 1:nrow(artist_means)) + xaxis_text(angle = 90, hjust = 1) "],["no-pooled-model.html", "16.3 No pooled model", " 16.3 No pooled model ggplot(spotify, aes(x = popularity, group = artist)) + geom_density() Key points: popularity can differ from one artist to an other some artist have a “stable” popularity across their song and some not Let change our model to reflect that: \\[Y_{ij}|\\mu_j, \\sigma \\sim N(\\mu_{j}, \\sigma^2 ) \\] \\(\\mu_{j}\\) : mean song popularity for artist \\(j\\) \\(\\sigma\\) : standard deviation in popularity from song to song within each artist spotify_no_pooled &lt;- stan_glm( popularity ~ artist - 1, data = spotify, family = gaussian, prior = normal(50, 2.5, autoscale = TRUE), prior_aux = exponential(1, autoscale = TRUE), chains = 4, iter = 5000*2, seed = 84735) 16.3.1 Same Quiz but with no pooling!! 3 artist: Mia X, artist with the lowest mean popularity in our data set Beyoncé, artist with nearly the highest mean popularity in our data set Mohsen Beats, an artist not in out data set set.seed(84735) predictions_no &lt;- posterior_predict( spotify_no_pooled, newdata = artist_means) # Plot the posterior predictive intervals ppc_intervals(artist_means$popularity, yrep = predictions_no, prob_outer = 0.80) + ggplot2::scale_x_continuous(labels = artist_means$artist, breaks = 1:nrow(artist_means)) + xaxis_text(angle = 90, hjust = 1) Two drawbacks: Ignoring other artist when modeling for one specific artist (what happens when fewer data point) If we assume no other artists help us understanding popularity of a specific artist we can not generalize to artist outside of our data set. "],["building-the-hierarchical-model.html", "16.4 Building the hierarchical model", " 16.4 Building the hierarchical model 16.4.1 The hierarchy Layer 1: \\(Y_{ij} | \\mu_j , \\sigma_y\\) how song popularity varies WITHIN artist \\(j\\) Layer 2: \\(\\mu_{j}|\\mu, \\sigma_\\mu\\) how typical popularity \\(\\mu_{j}\\) varies BETWEEN artists Layer 3: \\(\\mu, \\sigma_y, \\sigma_{\\mu}\\) prior models for shared global parameters (order do not necessarily matter) Layer 1: \\[Y_{ij}|\\mu_j, \\sigma_j \\sim N(\\mu_j, \\sigma_y^2)\\] \\(\\mu_j\\) mean song popularity for artist j \\(\\sigma_y\\) within group variability sd in popularity from song to song within each artist -&gt; if we stop here we have a “no pooled” Layer 2: \\[\\mu_{j}|\\mu_{j}. \\sigma_\\mu \\overset{ind}{\\sim} N(\\mu, \\sigma_\\mu^2)\\] \\(\\mu\\) global average: the means popularity ratings for the most average artist \\(\\sigma_{u}\\) \\(between-group variability\\), the standard deviation in mean popularity \\(μj\\) from artist to artist. #Normal is not too bad ggplot(artist_means, aes(x = popularity)) + geom_density() Layer 3 : Priors \\[\\mu \\sim N(50, 52^2)\\] (this 52 ???) \\[\\sigma_y \\sim Exp(0.048) \\] \\[ \\sigma \\sim Exp(1)\\] @realHollanders This is a one way analyis of variance (ANOVA) An other way to think about it: \\[Y_{ij}|\\mu_j, \\sigma_j \\sim N(\\mu_j, \\sigma_y^2) \\quad with \\quad \\mu_j = \\mu +b_j\\] \\[b_j | \\sigma_\\mu \\overset{ind}{\\sim} N(0, \\sigma_\\mu^2) \\] Example: if \\(\\mu\\) = 55 and \\(\\mu_j\\) = 65 \\(b_j\\) = 10 16.4.2 within- vs -between-group variability Before we analyse just one source of variability (the individual level), now we have two sources (\\(\\sigma_\\mu, \\sigma_y\\)). The first one is the sqrt(variance) within the group (song of an artist) and the second is the sqrt(variance) between group. The total variance is : \\[Var(Y_{ij} = \\sigma²_y + \\sigma^2_u) \\] Other way of thinking about is: \\(\\frac{\\sigma^2_y}{\\sigma^2_\\mu + \\sigma^2_y}\\) proportion of total variance explained by difference within each group \\(\\frac{\\sigma^2_\\mu}{\\sigma^2_\\mu + \\sigma^2_y}\\) proportion of total variance explained by difference between groups You have correlation in song popularity of the same artist (within group). And assuming each groups are independant we get: \\[Cor(Y_{ij}, Y_{kj}) = \\frac{\\sigma^2_\\mu}{\\sigma^2_\\mu + \\sigma^2_y}\\] ## Posterior analysis 16.4.3 Posterior simulation 47 parameters: 44 artists specific parameters (\\(\\mu_{j}\\)) 3 global parameters (\\(\\mu, \\sigma_j, sigma_\\mu\\)) spotify_hierarchical &lt;- stan_glmer( popularity ~ (1 | artist), # this is the part that tell that artist is a group not a predictor data = spotify, family = gaussian, prior_intercept = normal(50, 2.5, autoscale = TRUE), prior_aux = exponential(1, autoscale = TRUE), prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1), # stuff we will learn chapter 17 suppose to be equivalent to Exp(1) chains = 4, iter = 5000*2, seed = 84735) # Confirm the prior tunings prior_summary(spotify_hierarchical) ## Priors for model &#39;spotify_hierarchical&#39; ## ------ ## Intercept (after predictors centered) ## Specified prior: ## ~ normal(location = 50, scale = 2.5) ## Adjusted prior: ## ~ normal(location = 50, scale = 52) ## ## Auxiliary (sigma) ## Specified prior: ## ~ exponential(rate = 1) ## Adjusted prior: ## ~ exponential(rate = 0.048) ## ## Covariance ## ~ decov(reg. = 1, conc. = 1, shape = 1, scale = 1) ## ------ ## See help(&#39;prior_summary.stanreg&#39;) for more details We need to check the success of MCMC (saving you time here) bayesplot::pp_check(spotify_hierarchical) + xlab(&quot;popularity&quot;) Let inspect our simulation: spotify_hierarchical_df &lt;- as.data.frame(spotify_hierarchical) dim(spotify_hierarchical_df) ## [1] 20000 47 16.4.4 Posterior analysis of global parameters \\(\\mu = (intercept)\\) \\(\\sigma_y = sigma\\) \\(\\sigma_\\mu² = Sigma[artist:(intercep),(Intercept)]\\) Attention! here this is the variance tidy(spotify_hierarchical, effects = &quot;fixed&quot; # for getting global , conf.int = TRUE, conf.level = 0.80) ## # A tibble: 1 × 5 ## term estimate std.error conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 52.5 2.41 49.3 55.6 tidy(spotify_hierarchical, effects = &quot;ran_pars&quot;) # PARameters and RANdomness or variability) ## # A tibble: 2 × 3 ## term group estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 sd_(Intercept).artist artist 15.2 ## 2 sd_Observation.Residual Residual 14.0 An other way: 15.1^2 / (15.1^2 + 14.0^2) # sigma_mu^2 / sigma_mu^2 + sigma_y^2 ## [1] 0.5377468 14.0^2 / (15.1^2 + 14.0^2) # sigma_y^2 / sigma_mu^2 + sigma_y^2 ## [1] 0.4622532 16.4.5 posterior analysis of group specific If you recall that \\(\\mu_j = \\mu + b_{j}\\) We have \\(\\mu\\) and \\(b_j\\) (check spotify_hierarchical_df) # RANdom Values artist_summary &lt;- tidy(spotify_hierarchical, effects = &quot;ran_vals&quot; , conf.int = TRUE, conf.level = 0.80) # Check out the results for the first &amp; last 2 artists # 80% intervall # this produce a summary artist_summary %&gt;% select(level, conf.low, conf.high) %&gt;% slice(1:2, 43:44) ## # A tibble: 4 × 3 ## level conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Mia_X -40.8 -23.2 ## 2 Chris_Goldarg -39.4 -26.9 ## 3 Lil_Skies 11.1 30.3 ## 4 Camilo 19.4 32.4 dim(artist_summary) ## [1] 44 7 Other way: combining simulations to simulate posterior of \\(\\mu_j\\) \\[\\mu_j = \\mu + b_{j} = (Intercept) + b[(Intercept) \\quad artist:j]\\] artist_chains &lt;- spotify_hierarchical |&gt; spread_draws(`(Intercept)`, b[,artist]) |&gt; mutate(mu_j = `(Intercept)` + b) ## Warning: `gather_()` was deprecated in tidyr 1.2.0. ## ℹ Please use `gather()` instead. ## ℹ The deprecated feature was likely used in the tidybayes package. ## Please report the issue at &lt;https://github.com/mjskay/tidybayes/issues/new&gt;. dim(artist_chains) ## [1] 880000 7 artist_chains |&gt; select(artist, `(Intercept)`, b, mu_j) |&gt; head(4) ## # A tibble: 4 × 4 ## # Groups: artist [4] ## artist `(Intercept)` b mu_j ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 artist:Alok 45.7 14.9 60.6 ## 2 artist:Atlas_Genius 45.7 3.17 48.9 ## 3 artist:Au/Ra 45.7 10.4 56.1 ## 4 artist:Beyoncé 45.7 27.6 73.4 # Get posterior summaries for mu_j artist_summary_scaled &lt;- artist_chains |&gt; select(-`(Intercept)`, -b) |&gt; mean_qi(.width = 0.80) |&gt; mutate(artist = fct_reorder(artist, mu_j)) # Check out the results artist_summary_scaled |&gt; select(artist, mu_j, .lower, .upper) |&gt; head(4) ## # A tibble: 4 × 4 ## artist mu_j .lower .upper ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 artist:Alok 64.3 60.2 68.3 ## 2 artist:Atlas_Genius 47.0 38.9 55.3 ## 3 artist:Au/Ra 59.5 52.1 67.0 ## 4 artist:Beyoncé 69.1 65.7 72.6 ggplot(artist_summary_scaled, aes(x = artist, y = mu_j, ymin = .lower, ymax = .upper)) + geom_pointrange() + xaxis_text(angle = 90, hjust = 1) 16.4.5.1 QUiz ! Similar posterior mean but different 80%CI ? "],["posterior-prediction-1.html", "16.5 Posterior prediction", " 16.5 Posterior prediction What will be the popularity of new song of artist j (two cases: artist in the data / unknown artist)? posterior_predict() exist but first we do it by “hand”! 16.5.1 First case: Frank Ocean (j=39) \\[Y^{i}_{new,j} | \\mu_j, \\sigma_y \\sim N(\\mu_j^{i}, (\\sigma^{(i)}_y)^2)\\] We have plenty of \\(\\mu^{i}_j\\) and \\(\\sigma^{(i)}_y\\) with two sources of variability : Not all song of Ocean are eqully popular (within-group sampling variability) we do not know the exact mean and variability of Ocean song (posterior variability) # Simulate Ocean&#39;s posterior predictive model set.seed(84735) ocean_chains &lt;- spotify_hierarchical_df |&gt; rename(b = `b[(Intercept) artist:Frank_Ocean]`) |&gt; select(`(Intercept)`, b, sigma) |&gt; mutate(mu_ocean = `(Intercept)` + b, y_ocean = rnorm(20000, mean = mu_ocean, sd = sigma)) # stuff that I always forget # Check it out head(ocean_chains, 3) ## (Intercept) b sigma mu_ocean y_ocean ## 1 45.73260 24.56671 14.11825 70.29930 79.71946 ## 2 45.96217 24.45931 13.14185 70.42148 68.79399 ## 3 47.42739 20.86424 15.57204 68.29163 80.45134 Then you summarize it: ocean_chains |&gt; mean_qi(y_ocean, .width = 0.80) ## # A tibble: 1 × 6 ## y_ocean .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 69.3 51.2 87.5 0.8 mean qi # to put into context # the range of a new song is wider tham the average of ocean artist_summary_scaled |&gt; filter(artist == &quot;artist:Frank_Ocean&quot;) ## # A tibble: 1 × 7 ## artist mu_j .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 artist:Frank_Ocean 69.4 66.6 72.2 0.8 mean qi 16.5.2 Posterior prediction for an observed group We do not have \\(\\mu_j\\) but we know new artist is an artist! And we now the range of mean popularity level among artist \\(N(\\mu, \\sigma_u)\\) and we have 44 artists. step 1: simulate \\(\\mu_{new_artist}\\) bt drawing into layer 2 of MCMC step 2: simulate song popularity with Layer 1 and \\(\\mu_{new_artist}\\) We are adding a new source of variability (not all artist are equally popular : between group) set.seed(84735) mohsen_chains &lt;- spotify_hierarchical_df |&gt; mutate(sigma_mu = sqrt(`Sigma[artist:(Intercept),(Intercept)]`), mu_mohsen = rnorm(20000, `(Intercept)`, sigma_mu), # new stuff y_mohsen = rnorm(20000, mu_mohsen, sigma)) # Posterior predictive summaries mohsen_chains |&gt; mean_qi(y_mohsen, .width = 0.80) ## # A tibble: 1 × 6 ## y_mohsen .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 52.3 25.9 78.6 0.8 mean qi 16.5.3 posterior_predict() set.seed(84735) prediction_shortcut &lt;- posterior_predict( spotify_hierarchical, newdata = data.frame(artist = c(&quot;Frank Ocean&quot;, &quot;Mohsen Beats&quot;))) # Posterior predictive model plots mcmc_areas(prediction_shortcut, prob = 0.8) + ggplot2::scale_y_discrete(labels = c(&quot;Frank Ocean&quot;, &quot;Mohsen Beats&quot;)) ## Scale for y is already present. ## Adding another scale for y, which will replace the existing scale. "],["shrinkage-bias_variance-trade-off.html", "16.6 Shrinkage &amp; bias_variance trade-off", " 16.6 Shrinkage &amp; bias_variance trade-off set.seed(84735) predictions_hierarchical &lt;- posterior_predict(spotify_hierarchical, newdata = artist_means) # Posterior predictive plots ppc_intervals(artist_means$popularity, yrep = predictions_hierarchical, prob_outer = 0.80) + ggplot2::scale_x_continuous(labels = artist_means$artist, breaks = 1:nrow(artist_means)) + xaxis_text(angle = 90, hjust = 1) + geom_hline(yintercept = 58.4, linetype = &quot;dashed&quot;) Quizz What is shringage in this example ? Shrinkage refers to the phenomenon in which the group-specific local trends in a hierarchical model are pulled or shrunk toward the global trends. Shrinkage increases as the number of observations on group j, nj, decreases. That is, we rely more and more on global trends to understand a group for which we have little data. Shrinkage increases when the variability within groups, σy, is large in comparison to the variability between groups, σμ. That is, we rely more and more on global trends to understand a group when there is little distinction in the patterns from one group to the next The artists that shrunk the most are those with smaller sample sizes nj and popularity levels at the extremes of the spectrum. 16.6.1 Quizzz! With no pooled, complete pooled and hierarchical: Same population, other sample: which would be the most/least variable? Most biased/least estinating artist mean popularity levels? "],["not-everything-is-hierarchical.html", "16.7 Not everything is hierarchical", " 16.7 Not everything is hierarchical Distinction between a predictor and a grouping variable can only be made if we understand how data was collected. "],["summary-6.html", "16.8 Summary", " 16.8 Summary First model with groups! observations on one group are independent to another group but correlated in the same group New parameters : group-specific global parameters learning for one group to another will lead to some shrinkage this models are less variable than no pooling and less biased than complete pooling "],["meeting-videos-15.html", "16.9 Meeting Videos", " 16.9 Meeting Videos 16.9.1 Cohort 1 16.9.2 Cohort 2 Meeting chat log LOG 16.9.3 Cohort 3 Meeting chat log LOG "],["normal-hierarchical-models-with-predictors.html", "Chapter 17 (Normal) Hierarchical Models with Predictors", " Chapter 17 (Normal) Hierarchical Models with Predictors Learning objectives: Build hierarchical (H) regression models of response variable \\(Y\\) by predictors \\(X\\) Evaluate and compare H and non H models Use H models for posterior prediction 17.0.1 Data set We are returning on a subset of the Cherry Blossom 10 mile running race analysis # Load packages library(bayesrules) library(tidyverse) library(rstanarm) library(bayesplot) library(tidybayes) library(broom.mixed) # Load data data(cherry_blossom_sample) running &lt;- cherry_blossom_sample A bit of data wrangling: running &lt;- running |&gt; select(runner, age, net) |&gt; na.omit() nrow(running) ## [1] 185 unique(running$runner) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 27 28 29 30 31 32 33 34 35 36 ## 36 Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ... 36 We have 36 runners and 185 rows. "],["quick-complete-pooling-option.html", "17.1 Quick: complete pooling option", " 17.1 Quick: complete pooling option \\[Y_{ij} | \\beta_0, \\beta_1, \\sigma \\sim N(\\mu_i, \\sigma^2)\\] \\(Y_{ij}\\) running time with \\(j\\) runner and \\(i\\) race \\[\\mu_i = \\beta_0 + \\beta_1X_{ij}\\] \\(X_{ij}\\) Age Then we have global parameters (also here priors) \\[\\beta_{0c} \\sim N (0, 35^2)\\] This is the intercept centered \\[\\beta_1 \\sim N(0, 15^2)\\] \\[\\sigma \\sim Exp(0,072)\\] If we go with this model: no relationship between age and running time. complete_pooled_model &lt;- stan_glm( net ~ age, data = running, family = gaussian, prior_intercept = normal(0, 2.5, autoscale = TRUE), prior = normal(0, 2.5, autoscale = TRUE), prior_aux = exponential(1, autoscale = TRUE), chains = 4, iter = 5000*2, seed = 84735) ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 2e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 1: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 1: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 1: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 1: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 1: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 1: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 1: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 1: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 1: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 1: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 1: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.120245 seconds (Warm-up) ## Chain 1: 0.227351 seconds (Sampling) ## Chain 1: 0.347596 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 1.5e-05 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 2: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 2: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 2: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 2: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 2: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 2: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 2: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 2: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 2: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 2: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 2: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.124331 seconds (Warm-up) ## Chain 2: 0.22343 seconds (Sampling) ## Chain 2: 0.347761 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 1.5e-05 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 3: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 3: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 3: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 3: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 3: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 3: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 3: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 3: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 3: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 3: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 3: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.125701 seconds (Warm-up) ## Chain 3: 0.216206 seconds (Sampling) ## Chain 3: 0.341907 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 1.5e-05 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 4: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 4: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 4: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 4: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 4: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 4: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 4: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 4: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 4: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 4: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 4: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 0.120261 seconds (Warm-up) ## Chain 4: 0.20965 seconds (Sampling) ## Chain 4: 0.329911 seconds (Total) ## Chain 4: "],["hierarchical-model-with-varying-intercept.html", "17.2 Hierarchical Model with varying intercept", " 17.2 Hierarchical Model with varying intercept 17.2.1 Model buildings 17.2.1.1 Layer 1 Within-group: within runner \\[Y_{ij} | \\beta_0, \\beta_1, \\sigma_j \\sim N(\\mu_{ij}, \\sigma_j^2)\\] We added a bunch of \\(j\\)! So now we have runner specific mean (\\(\\mu_{ij}\\)) and the variance with a runner (\\(\\sigma_j\\)) \\[\\mu_{ij} = \\beta_{0j} + \\beta_1X_{ij}\\] Here we are using a specific intercept for each runner (\\(\\beta_{oj}\\)) but we are still using a global age coefficient (\\(\\beta_1\\)). 17.2.1.2 Layer 2: Between Runners Quizz! Which of our current parameters (\\(\\beta_{0j}, \\beta_1, \\sigma_y\\)) do we need to model in the next layer? (hint:title) \\[\\beta_{0j} | \\beta_{0}, \\sigma_0 \\overset{\\text{ind}}{\\sim} N(\\beta_0, \\sigma_0^2)\\] \\(\\beta_{0j}\\) is our intercept for each runner and it follow a normal distribution with the global average of intercept (\\(\\beta_0\\)) and the between-group variability (\\(\\sigma_0\\)). Now quiz! For Which model parameters must we specify priors in the final layer of our hierarchical regression model? \\[\\beta_{0c} \\sim N(m_0, s_0^2)\\] \\[\\beta_1 \\sim N(m_1, s_1^2)\\] \\[\\sigma_y \\sim Exp(l_y)\\] \\[\\sigma_0 \\sim Exp(l_0)\\] Normal hierarchical regression assumptions: structure of the data: conditioned on \\(X_{ij}\\), \\(Y_{ij}\\) on any group j is independant of other group k but different data point within the same group are correlated structure of the relationship: Linear relation structure of variability within groups: Within any group j at any predictor value \\(X_{ij}\\) the observed values of \\(Y_{ij}\\) will vary normally Structure of variability between groups 17.2.1.3 Tuning the prior \\[\\beta_{0c} \\sim N(100, 10^2)\\] runing tine is around 80 - 120 mins \\[\\beta_1 \\sim N(2.5, 1^2)\\] We just know that it increase and it can range from 0.5 to 4.5 mins / year (on average) \\[\\sigma_y \\sim Exp(0.078)\\] \\[\\sigma_0 \\sim Exp(1)\\] Then we use weakly informative priors. running_model_1_prior &lt;- stan_glmer( net ~ age + (1 | runner), # formula data = running, family = gaussian, prior_intercept = normal(100, 10), prior = normal(2.5, 1), prior_aux = exponential(1, autoscale = TRUE), prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1), chains = 4, iter = 5000*2, seed = 84735, prior_PD = TRUE) # just the prior ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 2.4e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 1: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 1: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 1: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 1: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 1: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 1: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 1: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 1: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 1: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 1: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 1: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.472834 seconds (Warm-up) ## Chain 1: 0.495713 seconds (Sampling) ## Chain 1: 0.968547 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 1.9e-05 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 2: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 2: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 2: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 2: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 2: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 2: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 2: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 2: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 2: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 2: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 2: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.467683 seconds (Warm-up) ## Chain 2: 0.496071 seconds (Sampling) ## Chain 2: 0.963754 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 1.7e-05 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 3: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 3: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 3: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 3: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 3: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 3: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 3: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 3: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 3: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 3: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 3: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.478301 seconds (Warm-up) ## Chain 3: 0.508616 seconds (Sampling) ## Chain 3: 0.986917 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 1.8e-05 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 4: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 4: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 4: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 4: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 4: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 4: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 4: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 4: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 4: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 4: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 4: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 0.47228 seconds (Warm-up) ## Chain 4: 0.493333 seconds (Sampling) ## Chain 4: 0.965613 seconds (Total) ## Chain 4: running |&gt; # here we just used 100 sims add_predicted_draws(running_model_1_prior, n = 100) |&gt; ggplot(aes(x = net)) + geom_density(aes(x = .prediction, group = .draw)) + xlim(-100,300) ## Warning: ## In add_predicted_draws(): The `n` argument is a deprecated alias for `ndraws`. ## Use the `ndraws` argument instead. ## See help(&quot;tidybayes-deprecated&quot;). ## Warning: Removed 46 rows containing non-finite values (`stat_density()`). "],["posterior-simulation-and-analysis.html", "17.3 Posterior simulation and analysis", " 17.3 Posterior simulation and analysis # Simulate the posterior !!! new command you can set/update running_model_1 &lt;- update(running_model_1_prior, prior_PD = FALSE) ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 6.6e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.66 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 1: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 1: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 1: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 1: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 1: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 1: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 1: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 1: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 1: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 1: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 1: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 3.62072 seconds (Warm-up) ## Chain 1: 3.41978 seconds (Sampling) ## Chain 1: 7.0405 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 4.5e-05 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 2: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 2: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 2: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 2: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 2: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 2: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 2: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 2: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 2: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 2: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 2: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 3.69792 seconds (Warm-up) ## Chain 2: 3.41076 seconds (Sampling) ## Chain 2: 7.10868 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 4.1e-05 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 3: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 3: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 3: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 3: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 3: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 3: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 3: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 3: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 3: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 3: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 3: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 3.67161 seconds (Warm-up) ## Chain 3: 3.50038 seconds (Sampling) ## Chain 3: 7.17199 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 3.9e-05 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 10000 [ 0%] (Warmup) ## Chain 4: Iteration: 1000 / 10000 [ 10%] (Warmup) ## Chain 4: Iteration: 2000 / 10000 [ 20%] (Warmup) ## Chain 4: Iteration: 3000 / 10000 [ 30%] (Warmup) ## Chain 4: Iteration: 4000 / 10000 [ 40%] (Warmup) ## Chain 4: Iteration: 5000 / 10000 [ 50%] (Warmup) ## Chain 4: Iteration: 5001 / 10000 [ 50%] (Sampling) ## Chain 4: Iteration: 6000 / 10000 [ 60%] (Sampling) ## Chain 4: Iteration: 7000 / 10000 [ 70%] (Sampling) ## Chain 4: Iteration: 8000 / 10000 [ 80%] (Sampling) ## Chain 4: Iteration: 9000 / 10000 [ 90%] (Sampling) ## Chain 4: Iteration: 10000 / 10000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 3.43093 seconds (Warm-up) ## Chain 4: 3.47053 seconds (Sampling) ## Chain 4: 6.90146 seconds (Total) ## Chain 4: # Check the prior specifications prior_summary(running_model_1) ## Priors for model &#39;running_model_1&#39; ## ------ ## Intercept (after predictors centered) ## ~ normal(location = 100, scale = 10) ## ## Coefficients ## ~ normal(location = 2.5, scale = 1) ## ## Auxiliary (sigma) ## Specified prior: ## ~ exponential(rate = 1) ## Adjusted prior: ## ~ exponential(rate = 0.072) ## ## Covariance ## ~ decov(reg. = 1, conc. = 1, shape = 1, scale = 1) ## ------ ## See help(&#39;prior_summary.stanreg&#39;) for more details # Markov chain diagnostics # mcmc_trace(running_model_1) # mcmc_dens_overlay(running_model_1) # mcmc_acf(running_model_1) # neff_ratio(running_model_1) # rhat(running_model_1) Data output and model: (Intercept) = \\(\\beta_0\\) age - \\(\\beta_1\\) b[(intercept) runner:j] = \\(b_{0j} = \\beta_{0j} - \\beta_0\\) sigma = \\(\\sigma_y\\) Sigma[runner:(Intercept), (Intercept)] = \\(\\sigma_0^2\\) 17.3.0.1 Posterior analysis of the global relationship \\[\\beta_0 + \\beta_1X\\] tidy_summary_1 &lt;- tidy(running_model_1, effects = &quot;fixed&quot;, conf.int = TRUE, conf.level = 0.80) tidy_summary_1 ## # A tibble: 2 × 5 ## term estimate std.error conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 19.3 12.0 3.78 34.9 ## 2 age 1.30 0.216 1.02 1.58 So runners are slowing down with age! 17.3.0.2 Posterior analysis of group-specific relationships \\[\\beta_{0j} + \\beta_1X_{ij} = (\\beta_0 + b_{0j}) + \\beta_1X_{ij} \\] # Posterior summaries of runner-specific intercepts # we go from wide to long runner_summaries_1 &lt;- running_model_1 |&gt; spread_draws(`(Intercept)`, b[,runner]) |&gt; mutate(runner_intercept = `(Intercept)` + b) |&gt; select(-`(Intercept)`, -b) |&gt; median_qi(.width = 0.80) |&gt; select(runner, runner_intercept, .lower, .upper) runner_summaries_1 ## # A tibble: 36 × 4 ## runner runner_intercept .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 runner:1 5.54 -10.1 21.0 ## 2 runner:10 43.9 27.9 59.9 ## 3 runner:11 19.4 4.02 34.7 ## 4 runner:12 1.09 -14.7 16.7 ## 5 runner:13 11.1 -4.41 26.9 ## 6 runner:14 24.0 8.14 39.7 ## 7 runner:15 25.8 10.4 41.1 ## 8 runner:16 23.6 8.00 38.8 ## 9 runner:17 29.5 14.1 44.7 ## 10 runner:18 31.5 15.9 46.8 ## # … with 26 more rows running |&gt; filter(runner %in% c(&quot;4&quot;, &quot;5&quot;)) |&gt; add_fitted_draws(running_model_1, n = 100) |&gt; ggplot(aes(x = age, y = net)) + geom_line( aes(y = .value, group = paste(runner, .draw), color = runner), alpha = 0.1) + geom_point(aes(color = runner)) ## Warning: `fitted_draws` and `add_fitted_draws` are deprecated as their names were confusing. ## Use [add_]epred_draws() to get the expectation of the posterior predictive. ## Use [add_]linpred_draws() to get the distribution of the linear predictor. ## For example, you used [add_]fitted_draws(..., scale = &quot;response&quot;), which ## means you most likely want [add_]epred_draws(...). 17.3.0.3 Posterior analysis of within- and between group variability tidy_sigma &lt;- tidy(running_model_1, effects = &quot;ran_pars&quot;) tidy_sigma ## # A tibble: 2 × 3 ## term group estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 sd_(Intercept).runner runner 13.3 ## 2 sd_Observation.Residual Residual 5.25 sigma_0 &lt;- tidy_sigma[1,3] sigma_y &lt;- tidy_sigma[2,3] sigma_0^2 / (sigma_0^2 + sigma_y^2) # between ## estimate ## 1 0.8653185 sigma_y^2 / (sigma_0^2 + sigma_y^2) # within ## estimate ## 1 0.1346815 "],["hierarchical-model-with-varying-intercepts-slopes.html", "17.4 Hierarchical model with varying intercepts &amp; slopes", " 17.4 Hierarchical model with varying intercepts &amp; slopes ggplot(running, aes(x = age, y = net, group = runner)) + geom_smooth(method = &quot;lm&quot;, se = FALSE, size = 0.5) ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## `geom_smooth()` using formula = &#39;y ~ x&#39; Quiz! source:thebrain187 How can we modify our random intercepts models to recognize that the rate at which running time change with age might vary from runner to runner? 17.4.1 Model building \\[Y_{ij} | \\beta_{0j}, \\beta_{1j}, \\sigma_y \\sim N(\\mu_{ij}, \\sigma_y^2)\\] \\[\\mu_{ij} = \\beta_{0j} + \\beta_{1j}X_{ij}\\] \\[\\beta_{0j} | \\beta_{0}, \\sigma_0 \\sim N(\\beta_0, \\sigma_0^2)\\] \\[\\beta_{1j} | \\beta_{1}, \\sigma_1 \\sim N(\\beta_1, \\sigma_1^2)\\] But \\(\\beta_{0j}\\) and \\(\\beta_{1j}\\) are correlated for runner j. Let \\(\\rho \\in [-1,1]\\) represent the correlation between \\(\\beta_{0j}\\) and \\(\\beta_(1j)\\). We will need to do a joint Normal model of both: \\[\\begin{pmatrix} \\beta_{0j} \\\\ \\beta_{1j} \\end{pmatrix} | \\beta_0, \\beta_1, \\sigma_0, \\sigma_1 \\sim N \\begin{pmatrix}\\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\end{pmatrix}, \\Sigma \\end{pmatrix}\\] \\[ \\Sigma = \\begin{pmatrix} \\sigma_0² &amp; \\rho\\sigma_0\\sigma_1 \\\\ \\rho\\sigma_0\\sigma_1 &amp; \\sigma_1^2 \\end{pmatrix} \\] \\(\\Sigma\\) is our covariance matrix Let me google it for you: \\[\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma_X\\sigma_y} \\in [-1, 1]\\] Examples: strong negative correlation between \\(\\beta_{0j}\\) and \\(\\beta_{1j}\\) with small intercept: smaller you start higher you go strong positive correlation with small intercept : smaller you start lower you go no correlation : X and Y do their life Quiz! \\(\\beta_{0j}\\) and \\(\\beta_{1j}\\) are negatively correlated: Runners that start out slower (i.e., with a higher baseline), also tend to slow down at a more rapid rate. The rate at which runners slow down over time isn’t associated with how fast they start out. Runners that start out faster (i.e., with a lower baseline), tend to slow down at a more rapid rate. \\(\\beta_{0j}\\) and \\(\\beta_{1j}\\) are positively correlated: If \\(\\sigma_1 = 0\\), age will not differ group to group we are back to the random intercepts model. But how do we get our Joint prior model? We are using a decomposition of covariance model and the function decov() (rememver the prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1) in our stan_glmer call) We can decompose our matrix in 3 components: \\[R = \\begin{pmatrix} 1 &amp; \\rho \\\\ \\rho &amp; 1 \\end{pmatrix}\\] \\[ \\tau = \\sqrt{\\sigma^2_0 + \\sigma^2_1}\\] \\[ \\pi = \\begin{pmatrix} \\pi_0 \\\\ \\pi_1 \\end{pmatrix} = \\begin{pmatrix}\\frac{\\sigma_0^2}{\\sigma_0^2 + \\sigma_1^2} \\\\ \\frac{\\sigma_1^2}{\\sigma_0^2 + \\sigma_1^2} \\end{pmatrix}\\] \\[R \\sim LKJ(\\eta)\\] Lewandowski-Kurowicka-Joe (LKJ) distribution with \\(\\eta\\) as **regularization hyperparameter if \\(\\eta &lt; 1\\) prior with strong correlation unsure of postive or negative if \\(\\eta = 1\\) flat prior between - 1 and 1 if \\(\\eta &gt; 1\\) prior indicating low correlation For \\(\\tau\\) we can use a Gamma prior (or here the exponential special case). It use two parameters : shape and scale. Finaly for \\(\\pi\\) we know that the sum of them will be one (remember they are the relative proportion of the variability between group). This means we will be able to use a symmetric Dirichlet(\\(2, \\delta\\)). \\(\\delta\\) is called a concentration hyperparameter. In this case with two group it can be define as a Beta distribution with both (\\(\\delta\\)). if \\(\\delta &lt; 1\\) more prior on \\(\\pi_0\\) on 0, 1 -&gt; either a lot of few of the variability between group is explained with intercept \\(\\delta = 1\\) flat prior on \\(\\pi_0\\) variability of the intercept can explain from 0 to all the variability between groups \\(\\delta &gt; 1\\) our prior is that around half of the variability between group is explained by differences in intercepts and rest with slopes. To sum it up when we use rstanarm decov(): reg = 1 is for \\(R \\sim LKJ(1)\\) shape = 1 , scale = 1 is for \\(\\tau \\sim Gamma(1,1)\\) or \\(Exp(1)\\) conc = 1 is for \\(Dirichlet(2,1)\\) (two parameters with \\(\\delta = 1\\)) 17.4.2 Posterior simulation and anlysis running_model_2 &lt;- stan_glmer( net ~ age + (age | runner), data = running, family = gaussian, prior_intercept = normal(100, 10), prior = normal(2.5, 1), prior_aux = exponential(1, autoscale = TRUE), prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1), chains = 4, iter = 5000*2, seed = 84735, adapt_delta = 0.99999 # change here ) Now we have 78 parameters (36 for intercepts / 36 age coefficient and 6 global parameters) ! My poor laptop have done it in 33 minutes! 17.4.2.1 Global / Group specific parameters : \\[\\beta_0 + \\beta_1 X \\] # Quick summary of global regression parameters tidy(running_model_2, effects = &quot;fixed&quot;, conf.int = TRUE, conf.level = 0.80) # A tibble: 2 x 5 term estimate std.error conf.low conf.high &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 18.5 11.6 3.61 33.6 2 age 1.32 0.217 1.04 1.59 We need to move the MCMC simulations result into a friendlier objet: # str(running_model_2) try it! runner_chains_2 &lt;- running_model_2 |&gt; spread_draws(`(Intercept)`, b[term, runner], `age`) |&gt; pivot_wider(names_from = term, names_glue = &quot;b_{term}&quot;, values_from = b) |&gt; mutate(runner_intercept = `(Intercept)` + `b_(Intercept)`, runner_age = age + b_age) dim(runner_chains_2) We need to summarize a bit: runner_summaries_2 &lt;- runner_chains_2 |&gt; group_by(runner) |&gt; summarize(runner_intercept = median(runner_intercept), runner_age = median(runner_age)) # Check it out head(runner_summaries_2, 3) saveRDS(runner_summaries_2, &quot;data/ch17/runner_summaries_2&quot;) runner_summaries_2 &lt;- readRDS(&quot;data/ch17/runner_summaries_2&quot;) ggplot(running, aes(y = net, x = age, group = runner)) + geom_abline(data = runner_summaries_2, color = &quot;gray&quot;, aes(intercept = runner_intercept, slope = runner_age)) + lims(x = c(50, 61), y = c(50, 135)) They slopes differ but no so much -&gt; shrinkage the model is still trying to balance between a complete pooled models and a no pooled one (see fig 17.16). 17.4.2.2 Within- and between-group variability is it worth it ? tidy(running_model_2, effects = &quot;ran_pars&quot;) # A tibble: 4 x 3 term group estimate &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 sd_(Intercept).runner runner 1.34 2 sd_age.runner runner 0.251 3 cor_(Intercept).age.runner runner -0.0955 4 sd_Observation.Residual Residual 5.17 We had 5.25 as \\(\\sigma_y\\) before, We have very slight correlation between \\(\\beta_0j\\) and \\(\\beta_1j\\). "],["model-evaluation-and-selection.html", "17.5 Model evaluation and selection", " 17.5 Model evaluation and selection How fair is each model? How wrong is each model? How accurate are each model posterior prediction? For 2: pp_check(complete_pooled_model) + labs(x = &quot;net&quot;, title = &quot;complete pooled model&quot;) pp_check(running_model_1) + labs(x = &quot;net&quot;, title = &quot;running model 1&quot;) # Not displaying because MCMC of running_model_2 is to slow # pp_check(running_model_2) + # labs(x = &quot;net&quot;, title = &quot;running model 2&quot;) We can drop the complete pooled model. # Calculate prediction summaries set.seed(84735) prediction_summary(model = running_model_1, data = running) mae mae_scaled within_50 within_95 1 2.626 0.456 0.6865 0.973 prediction_summary(model = running_model_2, data = running) mae mae_scaled within_50 within_95 1 2.53 0.4424 0.7027 0.973 they are very close! But what about “unknown data”? We will use CV but here we divide runners. (I did not run it as I was afraid of computation time!) Using expected log-predictive densities (ELPD) we do not find significant difference in posterior accuracy for the two models. Is the additional complexity worth it? Here no. "],["posterior-prediction-2.html", "17.6 Posterior prediction", " 17.6 Posterior prediction We will use running_model_1. We will try to predict for runner1, runner10 and Miles (one of the authors) when they will be 61 years old. running |&gt; filter(runner %in% c(&quot;1&quot;, &quot;10&quot;)) |&gt; ggplot(data = _ , aes(x = age, y = net)) + geom_point() + facet_grid(~ runner) + lims(x = c(54, 61)) ## Warning: Removed 1 rows containing missing values (`geom_point()`). We will have two sources of uncertainty in runner 1 and 10 (within-group sampling variability \\(\\sigma_y\\), posterior variability, \\(\\beta_{0j}\\), \\(\\beta_1\\) and \\(\\sigma_y\\)) and for Miles we need to add the between-group sampling variability (\\(\\sigma_0\\)). set.seed(84735) predict_next_race &lt;- posterior_predict( running_model_1, newdata = data.frame(runner = c(&quot;1&quot;, &quot;Miles&quot;, &quot;10&quot;), age = c(61, 61, 61))) apply(predict_next_race, 2, median) ## 1 2 3 ## 84.57572 98.12049 122.99916 mcmc_areas(predict_next_race, prob = 0.8) + ggplot2::scale_y_discrete(labels = c(&quot;runner 1&quot;, &quot;Miles&quot;, &quot;runner 10&quot;)) ## Scale for y is already present. ## Adding another scale for y, which will replace the existing scale. "],["details-longitudinal-data.html", "17.7 Details: Longitudinal data", " 17.7 Details: Longitudinal data We observe each runner over time are are interest in effect of time: age is longitudinal. We are making the assumptions that our correlation will be the same across all ages we do not take into account that age close to each other tend to be more correlated. It is possible to add that into our model for that see bayeslongitudinal R package. "],["example-danceability.html", "17.8 Example Danceability", " 17.8 Example Danceability Next week ? "],["chapter-summary-1.html", "17.9 Chapter summary", " 17.9 Chapter summary \\(Y_{ij}|\\beta_j, \\sigma_y \\sim N(\\mu_{ij}, \\sigma²_y)\\) : regression model within group \\(j\\) \\(\\beta_j|\\beta, \\sigma \\sim N(\\beta, \\sigma^2)\\) : variability in regression parameters between group \\(\\beta, \\sigma_y, \\sigma, ... \\sim ...\\) priors models on global parameters Either we go with a random intercepts models or we use a random intercepts and slopes model. "],["meeting-videos-16.html", "17.10 Meeting Videos", " 17.10 Meeting Videos 17.10.1 Cohort 1 17.10.2 Cohort 2 Meeting chat log LOG 17.10.3 Cohort 3 Meeting chat log LOG "],["non-normal-hierarchical-regression-classification.html", "Chapter 18 Non-Normal Hierarchical Regression &amp; Classification", " Chapter 18 Non-Normal Hierarchical Regression &amp; Classification Learning objectives: Get familiar with basic modeling building blocks Expand generalized hierarchical regression model by combining hierarchical regression techniques with Poisson and Negative Binomial regression models and logistic regression models learn more about mountain climber success in Himalaya "],["introduction.html", "18.1 Introduction", " 18.1 Introduction In this chapter we will be looking at applying bayes rules on Himalayan data for the Himalayan Climbing Expeditions. Figure 18.1: The himalayan database: mountain climber success "],["hierarchical-logistic-regression.html", "18.2 Hierarchical logistic regression", " 18.2 Hierarchical logistic regression # Load packages library(bayesrules) library(tidyverse) library(bayesplot) library(rstanarm) library(tidybayes) library(broom.mixed) library(janitor) climbers &lt;- climbers_sub %&gt;% select(expedition_id, member_id, success, year, season, age, expedition_role, oxygen_used) Data are from The Himalayan Database, Himalayan Climbing Expeditions data shared through the #tidytuesday project R for Data Science 2020b, made of 2076 climbers, dating back to 1978. # Import, rename, &amp; clean data data(climbers_sub) climbers &lt;- climbers_sub %&gt;% select(expedition_id, member_id, success, year, season, age, expedition_role, oxygen_used) nrow(climbers) ## [1] 2076 climbers%&gt;%head # A tibble: 6 × 8 expedition_id member_id success year season age expedition_role oxygen…¹ &lt;chr&gt; &lt;fct&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;lgl&gt; 1 AMAD81101 AMAD81101-03 TRUE 1981 Spring 28 Climber FALSE 2 AMAD81101 AMAD81101-04 TRUE 1981 Spring 27 Exp Doctor FALSE 3 AMAD81101 AMAD81101-02 TRUE 1981 Spring 35 Deputy Leader FALSE 4 AMAD81101 AMAD81101-05 TRUE 1981 Spring 37 Climber FALSE 5 AMAD81101 AMAD81101-06 TRUE 1981 Spring 43 Climber FALSE 6 AMAD81101 AMAD81101-07 FALSE 1981 Spring 38 Climber FALSE # … with abbreviated variable name ¹​oxygen_used To generate a frequency table we use the tabyl() function: ?janitor::tabyl climbers %&gt;% janitor::tabyl(success) success n percent FALSE 1269 0.6112717 TRUE 807 0.3887283 # Size per expedition climbers_per_expedition &lt;- climbers %&gt;% count(expedition_id) # Number of expeditions nrow(climbers_per_expedition) ## [1] 200 The individual climber outcomes are independent. climbers_per_expedition %&gt;% head(3) ## # A tibble: 3 × 2 ## expedition_id n ## &lt;chr&gt; &lt;int&gt; ## 1 AMAD03107 5 ## 2 AMAD03327 6 ## 3 AMAD05338 12 More than 75 of our 200 expeditions had a 0% success rate. In contrast, nearly 20 expeditions had a 100% success rate. There’s quite a bit of variability in expedition success rates. # Calculate the success rate for each exhibition expedition_success &lt;- climbers %&gt;% group_by(expedition_id) %&gt;% summarize(success_rate = mean(success)) Figure 18.2: Histogram of the success rates for the 200 climbing expeditions 18.2.1 Model building &amp; simulation We use the Bernoulli model for binary response variable: expedtion success \\[Y_{ij}=\\left\\{\\begin{matrix} 0 &amp; \\text{yes} \\\\ 1 &amp; \\text{no} \\end{matrix}\\right.\\] \\[X_{ij1}= \\text{age of climber j in expedition j}\\] \\[X_{ij2}= \\text{climber i received oxygen in expedition j}\\] Bayesian model \\[Y_{ij}|\\pi_{ij}\\sim Bern(\\pi_{ij})\\] Complete pooling expands this simple model into a logistic regression model \\[Y_{ij}|\\beta_0,\\beta_1,\\beta_2\\overset{ind}\\sim Bern(\\pi_{ij})\\] with \\(\\beta_0\\) the typical baseline success rate across all expeditions \\(\\beta_1\\) the global relationship between success and age when controlling for oxygen use \\(\\beta_2\\) the global relationship between success and oxygen use when **controlling for age \\[log(\\frac{\\pi_{ij}}{1-\\pi_{ij}})=\\beta_0+\\beta_1X_{ij1}+\\beta_2X_{ij2}\\] We need to take account for the grouping structure of our data. # Calculate the success rate by age and oxygen use data_by_age_oxygen &lt;- climbers %&gt;% group_by(age, oxygen_used) %&gt;% summarize(success_rate = mean(success),.groups=&quot;drop&quot;) Figure 18.3: Scatterplot of the success rate among climbers by age and oxygen use We substitute \\(\\beta_0\\) with the centered intercept \\(\\beta_{0c}\\). \\[\\beta_{0c}\\sim N(m_0,s_0^2)\\] \\(m_0=0\\) and \\(s_0^2=2.5^2\\), \\(s_1^2=0.24^2\\), \\(s_2^2=5.51^2\\) \\[\\beta_{0j}|\\beta_0,\\sigma_0\\overset{ind}\\sim N(\\beta_0,s_0^2)\\] and, \\[\\sigma_0\\sim Exp(1)\\] Reframe the random intercepts logistic regression model as a tweaks to the global intercept: \\[log(\\frac{\\pi_{ij}}{1-\\pi_{ij}})=(\\beta_0+b_{0j})+\\beta_1X_{ij1}+\\beta_2X_{ij2}\\] \\(b_{0j}\\) depends on the variability \\[b_{0j}|\\sigma_0\\overset{ind}\\sim N(0,\\sigma_0^2)\\] \\(\\sigma_0\\) captures the between-group variability in success rates from expedition to expedition Set the model formula to hierarchical grouping structure: success ~ age + oxygen_used + (1 | expedition_id) climb_model &lt;- stan_glmer( success ~ age + oxygen_used + (1 | expedition_id), data = climbers, family = binomial, prior_intercept = normal(0, 2.5, autoscale = TRUE), prior = normal(0, 2.5, autoscale = TRUE), prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1), chains = 4, iter = 5000*2, seed = 84735 ) Confirm prior specifications prior_summary(climb_model) MCMC diagnostics mcmc_trace(climb_model, size = 0.1) mcmc_dens_overlay(climb_model) mcmc_acf(climb_model) neff_ratio(climb_model) rhat(climb_model) Define success rate function success_rate &lt;- function(x){mean(x == 1)} Posterior predictive check pp_check(climb_model, nreps = 100, plotfun = &quot;stat&quot;, stat = &quot;success_rate&quot;) + xlab(&quot;success rate&quot;) (#fig:18-pp_check_fig)The histogram displays the proportion of climbers that were successful in each of 100 posterior simulated datasets 18.2.2 Posterior analysis Posterior summaries for our global regression parameters reveal that the likelihood of success decreases with age. tidy(climb_model, effects = &quot;fixed&quot;, conf.int = TRUE, conf.level = 0.80) Confidence intervals are expressed as the log(odds) to the odds scale, so will be converted to: \\[(e^{-conf.low},e^{-conf.high})=(a,b)\\] On the probability of success scale \\[\\pi=\\frac{e^{-\\beta_0-\\beta_1X_1+\\beta_2X_2}}{1+e^{-\\beta_0-\\beta_1X_1+\\beta_2X_2}}\\] Results are: both with oxygen and without, the probability of success decreases with age. climbers %&gt;% add_fitted_draws(climb_model, n = 100, re_formula = NA) %&gt;% ggplot(aes(x = age, y = success, color = oxygen_used)) + geom_line(aes(y = .value, group = paste(oxygen_used, .draw)), alpha = 0.1) + labs(y = &quot;probability of success&quot;) 18.2.3 Posterior classification New expedition new_expedition &lt;- data.frame( age = c(20, 20, 60, 60), oxygen_used = c(FALSE, TRUE, FALSE, TRUE), expedition_id = rep(&quot;new&quot;, 4)) new_expedition ## age oxygen_used expedition_id ## 1 20 FALSE new ## 2 20 TRUE new ## 3 60 FALSE new ## 4 60 TRUE new Posterior predictions of binary outcome set.seed(84735) binary_prediction &lt;- posterior_predict(climb_model, newdata = new_expedition) # First 3 prediction sets head(binary_prediction, 3) ## 1 2 3 4 ## [1,] 0 1 0 1 ## [2,] 0 1 0 0 ## [3,] 0 1 0 1 Summarize the posterior predictions of Y colMeans(binary_prediction) ## 1 2 3 4 ## 0.28470 0.80185 0.14755 0.64565 18.2.4 Model evaluation set.seed(84735) classification_summary(data = climbers, model = climb_model, cutoff = 0.5) set.seed(84735) classification_summary(data = climbers, model = climb_model, cutoff = 0.65) "],["hierarchical-poisson-negative-binomial-regression.html", "18.3 Hierarchical Poisson &amp; Negative Binomial regression", " 18.3 Hierarchical Poisson &amp; Negative Binomial regression # Load data data(airbnb) # Number of listings nrow(airbnb) ## [1] 1561 # Number of neighborhoods airbnb %&gt;% summarize(nlevels(neighborhood)) ## nlevels(neighborhood) ## 1 43 # nlevels(neighborhood) 18.3.1 Model building &amp; simulation ggplot(airbnb, aes(x = reviews)) + geom_histogram(color = &quot;white&quot;, breaks = seq(0, 200, by = 10)) ggplot(airbnb, aes(y = reviews, x = rating)) + geom_jitter() ggplot(airbnb, aes(y = reviews, x = room_type)) + geom_violin() airbnb %&gt;% filter(neighborhood %in% c(&quot;Albany Park&quot;, &quot;East Garfield Park&quot;, &quot;The Loop&quot;)) %&gt;% ggplot(aes(y = reviews, x = rating, color = room_type)) + geom_jitter() + facet_wrap(~ neighborhood) airbnb_model_1 &lt;- stan_glmer( reviews ~ rating + room_type + (1 | neighborhood), data = airbnb, family = poisson, prior_intercept = normal(3, 2.5, autoscale = TRUE), prior = normal(0, 2.5, autoscale = TRUE), prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1), chains = 4, iter = 5000*2, seed = 84735 ) pp_check(airbnb_model_1) + xlim(0, 200) + xlab(&quot;reviews&quot;) airbnb_model_2 &lt;- stan_glmer( reviews ~ rating + room_type + (1 | neighborhood), data = airbnb, family = neg_binomial_2, prior_intercept = normal(3, 2.5, autoscale = TRUE), prior = normal(0, 2.5, autoscale = TRUE), prior_aux = exponential(1, autoscale = TRUE), prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1), chains = 4, iter = 5000*2, seed = 84735 ) pp_check(airbnb_model_2) + xlim(0, 200) + xlab(&quot;reviews&quot;) 18.3.2 Posterior analysis tidy(airbnb_model_2, effects = &quot;fixed&quot;, conf.int = TRUE, conf.level = 0.80) readRDS(&quot;data/ch18/airbnb2_tidy1.rds&quot;) tidy(airbnb_model_2, effects = &quot;ran_vals&quot;, conf.int = TRUE, conf.level = 0.80) %&gt;% select(level, estimate, conf.low, conf.high) %&gt;% filter(level %in% c(&quot;Albany_Park&quot;, &quot;East_Garfield_Park&quot;, &quot;The_Loop&quot;)) readRDS(&quot;data/ch18/airbnb2_tidy2.rds&quot;) Posterior predictions of reviews set.seed(84735) predicted_reviews &lt;- posterior_predict( airbnb_model_2, newdata = data.frame( rating = rep(5, 3), room_type = rep(&quot;Entire home/apt&quot;, 3), neighborhood = c(&quot;Albany Park&quot;, &quot;East Garfield Park&quot;, &quot;The Loop&quot;))) mcmc_areas(predicted_reviews, prob = 0.8) + ggplot2::scale_y_discrete( labels = c(&quot;Albany Park&quot;, &quot;East Garfield Park&quot;, &quot;The Loop&quot;)) + xlim(0, 150) + xlab(&quot;reviews&quot;) ## Scale for y is already present. ## Adding another scale for y, which will replace the existing scale. ## Scale for x is already present. ## Adding another scale for x, which will replace the existing scale. ## Warning: Removed 3 rows containing missing values (`geom_segment()`). 18.3.3 Model evaluation set.seed(84735) pred &lt;- prediction_summary(model = airbnb_model_2, data = airbnb) pred ## mae mae_scaled within_50 within_95 ## 1 17.66115 0.6740938 0.5188981 0.9577194 "],["meeting-videos-17.html", "18.4 Meeting Videos", " 18.4 Meeting Videos 18.4.1 Cohort 1 Meeting chat log 00:32:12 Brendan Lam: “glimmer” sounds good 00:36:55 defuneste: tue sound cools 00:37:00 defuneste: true* 00:41:52 Federica Gazzelloni: https://cran.r-project.org/web/packages/tidybayes/vignettes/tidy-rstanarm.html 01:03:21 Brendan Lam: Thank you! 18.4.2 Cohort 2 Meeting chat log LOG 18.4.3 Cohort 3 Meeting chat log LOG "],["adding-more-layers.html", "Chapter 19 Adding More Layers", " Chapter 19 Adding More Layers Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-6.html", "19.1 SLIDE 1", " 19.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-18.html", "19.2 Meeting Videos", " 19.2 Meeting Videos 19.2.1 Cohort 1 Meeting chat log 00:13:18 defuneste: no worries 00:44:06 defuneste: https://theeffectbook.net/ 00:44:26 Brendan Lam: Looks interesting! 00:47:58 Federica Gazzelloni: https://www.paulamoraga.com/book-geospatial/ 00:48:25 defuneste: https://www.paulamoraga.com/book-geospatial/ 00:49:17 Federica Gazzelloni: Search: #book_club-geohealth 00:50:50 Brendan Lam: me too 00:51:49 defuneste: ROS regression and other stories 19.2.2 Cohort 2 Meeting chat log LOG 19.2.3 Cohort 3 Meeting chat log LOG "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
